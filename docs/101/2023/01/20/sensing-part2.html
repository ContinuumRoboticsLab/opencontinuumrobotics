<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Sensing for Continuum Robots - Part 2 -</title>
<meta name="description" content="Today, we continue our introduction to sensing the state of a continuum robot. If you have missed Part I of the intro, look at last week’s blog post before you continue here!">


  <meta name="author" content="Jessica Burgner-Kahrs">
  
  <meta property="article:author" content="Jessica Burgner-Kahrs">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_GB">
<meta property="og:site_name" content="">
<meta property="og:title" content="Sensing for Continuum Robots - Part 2">
<meta property="og:url" content="https://www.opencontinuumrobotics.com/101/2023/01/20/sensing-part2.html">


  <meta property="og:description" content="Today, we continue our introduction to sensing the state of a continuum robot. If you have missed Part I of the intro, look at last week’s blog post before you continue here!">



  <meta property="og:image" content="https://www.opencontinuumrobotics.com/assets/images/posts/cr_101_sensing_p2_teaser.jpg">





  <meta property="article:published_time" content="2023-01-20T00:00:00-05:00">






<link rel="canonical" href="https://www.opencontinuumrobotics.com/101/2023/01/20/sensing-part2.html">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Open Continuum Robotics Project",
      "url": "https://www.opencontinuumrobotics.com/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title=" Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    
<link rel="apple-touch-icon" sizes="180x180" href="https://www.opencontinuumrobotics.com/assets/images/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://www.opencontinuumrobotics.com/assets/images/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://www.opencontinuumrobotics.com/assets/images/favicons/favicon-16x16.png">
<link rel="manifest" href="https://www.opencontinuumrobotics.com/assets/images/favicons/site.webmanifest">
<link rel="mask-icon" href="https://www.opencontinuumrobotics.com/assets/images/favicons/safari-pinned-tab.svg" color="#5bbad5">
<link rel="shortcut icon" href="https://www.opencontinuumrobotics.com/favicon.ico">
<meta name="msapplication-TileColor" content="#2d89ef">
<meta name="theme-color" content="#ffffff">

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-9L7XX6LPRC"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-9L7XX6LPRC');
</script>
  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/"><img src="/assets/images/openCRProject_logo_header.png" alt=""></a>
        
        <a class="site-title" href="/">
          
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/software/">Software</a>
            </li><li class="masthead__menu-item">
              <a href="/hardware/">Hardware</a>
            </li><li class="masthead__menu-item">
              <a href="/blog/">Blog</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      
        <img src="/assets/images/jbk.png" alt="Jessica Burgner-Kahrs" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">Jessica Burgner-Kahrs</h3>
    
    
      <div class="author__bio" itemprop="description">
        <p>Professor. Roboticist.</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name">University of Toronto, Canada</span>
        </li>
      

      
        
          
            <li><a href="mailto:jessica.burgnerkahrs@utoronto.ca" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span></a></li>
          
        
          
            <li><a href="https://www.cs.toronto.edu/~jbk/" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-link" aria-hidden="true"></i><span class="label">Website</span></a></li>
          
        
      

      

      

      

      
        <li>
          <a href="https://twitter.com/BurgnerKahrs" itemprop="sameAs" rel="nofollow noopener noreferrer">
            <i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i><span class="label">Twitter</span>
          </a>
        </li>
      

      

      
        <li>
          <a href="https://www.linkedin.com/in/jessica-burgner-kahrs" itemprop="sameAs" rel="nofollow noopener noreferrer">
            <i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span class="label">LinkedIn</span>
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Sensing for Continuum Robots - Part 2">
    <meta itemprop="description" content="Today, we continue our introduction to sensing the state of a continuum robot. If you have missed Part I of the intro, look at last week’s blog post before you continue here!">
    <meta itemprop="datePublished" content="2023-01-20T00:00:00-05:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Sensing for Continuum Robots - Part 2
</h1>
          

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2023-01-20T00:00:00-05:00">2023-01-20</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          7 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#external-sensors">External Sensors</a><ul><li><a href="#coordinate-measurement">Coordinate Measurement</a></li><li><a href="#image-based-sensing">Image-based Sensing</a></li></ul></li><li><a href="#challenges">Challenges</a></li><li><a href="#sensing-in-a-nutshell">Sensing in a Nutshell</a></li></ul>

            </nav>
          </aside>
        
        <p>Today, we continue our introduction to sensing the state of a continuum robot. If you have missed Part I of the intro, look at <a href="/101/2023/01/13/sensing-part1.html">last week’s blog post</a> before you continue here!</p>

<p>To sense information about the state of a continuum robot, it may be desirable to not integrate sensors to the robot, but to use readily available external sensing methods.</p>

<h2 id="external-sensors">External Sensors</h2>
<p>The most common external sensing means for continuum robots are coordinate measurements using mechanical or laser probes and image-based techniques.</p>

<h3 id="coordinate-measurement">Coordinate Measurement</h3>
<p>A coordinate measuring machine/arm is used to measure the geometry of the robot by sensing discrete points on its surface using a probe. There exist two common types of probes typically used for continuum robots: mechanical probes and laser probes.</p>

<p><strong>Mechanical Probes:</strong> To acquire a measurement point, the robot has to be touched with the probe of the measurement arm which is usually operated manually by a user. This technique is suited to measure the position of the tip of the robot or to gather information on the shape of robot by measuring at multiple distinct locations along it.</p>

<p><img src="https://www.opencontinuumrobotics.com/assets/images/posts/cr_101_sensing_p2_discretePoints.png" alt="image" style="float: right" />
Mechanical probes provide high accuracies - usually sub-millimetre, but as operation is user-dependent the accuracy can vary. Mechanical probes are fast to setup and ready to use. But as the robot needs to be touched, it is challenging to not deform the robot while touching, which would lead to measurement errors and inconsistencies. As we are mostly interested in obtaining information about the centreline of the robot when we want to infer the shape, a coordinate measurement on the surface of the robot is suboptimal as it induces an offset to the centreline which has to be corrected for in post-processing. Lastly, mechanical probes for coordinate measurement are only suitable for static robot configurations and requires direct access to the robot.</p>

<p><strong>Laser Probes:</strong> To overcome the necessity of touching the robot for measuring coordinates, touch-less laser probes can be used, also referred to as 3D laser scanners. The laser probe is attached to the measurement arm and manually guided by the operator along the continuum robot. The laser probe emits a laser line and using the images from the camera within the probe, the distance of the scanned object from the probe can be determined. By sweeping the continuum robot, a point cloud of its structure can be obtained. This raw point cloud usually includes some noise as well as unwanted objects. Therefore, a post-processing step is performed to clean the data and eventually thin the point cloud in order to extract the shape.</p>

<p>Laser scanning has the advantage of providing dense information on the robot’s shape with contact-less acquisition. The precision of laser scanners is usually in the order of micrometers. This measurement technique is only suited for static cases, i.e., the continuum robot cannot move. Acquisition of the point cloud and post-processing can be quite time consuming. Lastly, this method also required direct line-of-sight, such that the continuum has to operate in free space.</p>

<h3 id="image-based-sensing">Image-based Sensing</h3>
<p>Image-based sensing employs mono- or stereoscopic cameras observing the robot fully or partially in its workspace. In robotics, an external camera is also referred to as eye-to-hand configuration. Using cameras observing the robot can be simply used to acquire image or video footage of robot motion in a qualitative manner, but it is more often applied to obtain quantitative measures. This requires additional processing of the images or video frames. Methods of computer vision, such as segmentation, 3D reconstruction using epipolar geometry, etc. are deployed to infer information on the robot’s tip position or pose as well as its shape. This information can then be used for visual servoing, also known as vision-based control, to control the motion of the continuum robot.</p>

<table>
  <tbody>
    <tr>
      <td><img src="https://www.opencontinuumrobotics.com/assets/images/posts/cr_101_sensing_p2_3dRecon.jpg" alt="image" /></td>
    </tr>
    <tr>
      <td>The shape of a continuum robot can be resonstructed using two cameras and epipolar geometry. Corresponding image coordinates representing a point on the robot have to be identified in both images, to determine the spatial position.</td>
    </tr>
  </tbody>
</table>

<p>The image or video-stream processing is dependent on the desired information but usually involves multiple steps. This is particularly challenging for small-scale continuum robots as the information in the image representing the robot in terms of pixels is sparse. Consequently, the resolution of the camera and the lens have to chosen wisely. While using artificial markers on the robot to ease image processing may be appealing, this becomes infeasible if the robot has very small diameter. In recent years, the continuum robotics community has seen some efforts in learning-based image processing, but the majority of techniques relies on classical computer vision.</p>

<p>External image-based sensing has the advantage of being contact-less, such that it can be deployed both for static and dynamic continuum robot applications. Cameras are readily available and 3D reconstruction from stereo or multiple cameras can be highly precise (sub-millimetre). Nevertheless, processing of images in real-time or reliable reconstruction are challenging and usually not working off-the-shelf. If considering dynamic measurement, synchronization of the image acquisition needs to be accounted for. A downside of image-based techniques is that direct line-of-sight is required, such that occlusions or partial views have to be avoided and accounted for in processing.</p>

<h2 id="challenges">Challenges</h2>
<p>Ideally, one would want to use as many sensors as possible and probably combine different modalities for their strengths while mitigating their limitations. Yet, it is impossible to have a multitude of sensors in a continuum robot given that there are many challenges in electronics, sensor size and space, wiring, powering, system integration, data communication and processing. Therefore, a smart sensor design and configuration strategy is needed to keep the number of sensors required to achieve a desired sensing capability low, and to optimize the sensor configuration for the best performance. Developing a sensor configuration strategy for continuum robots is particularly challenging because of their deformable body and high number of DOFs.</p>

<p>As of now, there is no way to directly measure forces and moments acting on a continuum robot. This information has to be inferred from other sensing modalities as discrete strain information. Force/torque sensors are commonly used in rigid-link robots but may not be available at small enough scale. One way to approach this is by measuring the actual shape of a continuum robot, for instance from images, EM tracking, or FGBs, and then comparing the measured shape with the expected shape from the robot’s kinematic or kinetostatic model. The observed deformation is a result from external forces and moments acting on the robot (assuming that the model is accurate). With assumptions on where forces/moments are acting (e.g. just at the tip), the model can be used to estimate those. While this is working in principal, the technique is still subject of ongoing research.</p>

<p>We have looked at the most prominent sensors used for continuum robots. Considering soft continuum robots, the development and integration of flexible and stretchable sensors is even more challenging. For instance, highly stretchable strain gauges composed of liquid metal micro channels can be directly embedded into the body of a silicone-based pneumatic actuator. They can then be used to measure the bending angle of the actuator. Yet, as soft continuum robots undergo large deformations, selecting the number of strain gauges, their location as well sensitivity is far from trivial.</p>

<p>Some areas of open research are concerned with continuous, real-time shape measurements of variable curvature, multi-section continuum robots, continuous force measurements along the robot’s body, and tactile sensing skins.</p>

<h2 id="sensing-in-a-nutshell">Sensing in a Nutshell</h2>
<p>As continuum robots are flexible bending/extending structures, sensing can be quite a challenge. The smaller the size of the continuum robot, the more challenging the sensor selection and its integration becomes. In our Sensing 101 <a href="/101/2023/01/13/sensing-part1.html">Part 1</a>  and <a href="/101/2023/01/20/sensing-part2.html">Part 2</a> blog posts, we have seen that multiple sensing modalities exist, each of which has its advantages and challenges. As no measurement technique is perfect and as no sensing modality suits all needs, the selection of sensors is a trade-off between application requirements and the particular continuum robot.</p>

<p>Some application areas, such as surgery, may also provide additional sensing means, such as medical imaging to reason about the position/pose or shape of a continuum robot operating within the human body (ultrasound, fluoroscopy, computed tomography, or magnetic resonance imaging). At the same time, applications may impose restrictions on which sensing modalities can be used. Think of a continuum robot for non-destructive inspection of a jet engine. Electromagnetic tracking would not be feasible in terms of range and external cameras would have no line-of-sight.</p>

        
      </section>

      <footer class="page__meta">
        
        


  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#101" class="page__taxonomy-item" rel="tag">101</a>
    
    </span>
  </p>


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2023-01-20T00:00:00-05:00">2023-01-20</time></p>


      </footer>

      <section class="page__share">
  

  <a href="https://twitter.com/intent/tweet?text=Sensing+for+Continuum+Robots+-+Part+2%20https%3A%2F%2Fwww.opencontinuumrobotics.com%2F101%2F2023%2F01%2F20%2Fsensing-part2.html" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.opencontinuumrobotics.com%2F101%2F2023%2F01%2F20%2Fsensing-part2.html" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Fwww.opencontinuumrobotics.com%2F101%2F2023%2F01%2F20%2Fsensing-part2.html" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/hands-on/2023/01/16/wrapWorld.html" class="pagination--pager" title="The string girdling Earth problem and how it relates to tendon displacement
">Previous</a>
    
    
      <a href="/hands-on/2023/01/24/openCRVis.html" class="pagination--pager" title="Visualizing Tendon-driven Continuum Robots in MATLAB
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/OpenCRProject1" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/ContinuumRoboticsLab" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2024 Open Continuum Robotics Project. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    <script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    },
    svg: {
      fontCache: 'global'
    }
  };
  </script>

  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
  </script>

  </body>
</html>
