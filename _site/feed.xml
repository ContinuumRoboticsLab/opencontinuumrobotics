<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://continuumroboticslab.github.io/opencontinuumrobotics/feed.xml" rel="self" type="application/atom+xml" /><link href="https://continuumroboticslab.github.io/opencontinuumrobotics/" rel="alternate" type="text/html" /><updated>2023-07-18T17:06:35-04:00</updated><id>https://continuumroboticslab.github.io/opencontinuumrobotics/feed.xml</id><title type="html">Open Continuum Robotics Project</title><subtitle>Open Continuum Robotics Project by the Continuum Robotics Laboratory, University of Toronto
Empowering everyone to build their own continuum robot and start their research.</subtitle><entry><title type="html">Introduction to Motion Planning for Continuum Robots - Part 2</title><link href="https://continuumroboticslab.github.io/opencontinuumrobotics/101/2023/06/28/intro-mp-part2.html" rel="alternate" type="text/html" title="Introduction to Motion Planning for Continuum Robots - Part 2" /><published>2023-06-28T00:00:00-04:00</published><updated>2023-06-28T00:00:00-04:00</updated><id>https://continuumroboticslab.github.io/opencontinuumrobotics/101/2023/06/28/intro-mp-part2</id><content type="html" xml:base="https://continuumroboticslab.github.io/opencontinuumrobotics/101/2023/06/28/intro-mp-part2.html">&lt;p&gt;Today, we continue our introduction to motion planning for continuum robots. If you have missed Part 1 of the intro, look at &lt;a href=&quot;/opencontinuumrobotics/101/2023/06/23/intro-mp-part1.html&quot;&gt;last week’s blog post&lt;/a&gt; before you continue here!&lt;/p&gt;

&lt;h2 id=&quot;what-makes-motion-planning-particularly-challenging-for-continuum-robots&quot;&gt;What makes motion planning particularly challenging for continuum robots?&lt;/h2&gt;
&lt;p&gt;First, let’s discuss one of the primary differences between continuum robots and more “traditional” robots (for lack of a better term)—modeling.&lt;/p&gt;

&lt;p&gt;As you’ve seen in prior (and future, I promise) blogs on this site, modeling the mechanics of continuum robots is fundamentally different from more traditional serial-link manipulator arms.&lt;/p&gt;

&lt;p&gt;As a subset of mechanics, consider just the forward kinematics (FK) problem for continuum robots, i.e., mapping the robot’s joint state to the robot’s resultant shape in space.
For concentric tube robots this may be mapping the robot’s tubes’ rotation/translation values to the robot’s shape and for tendon-driven robots this may be mapping the robot’s tendon tensions/displacements to the robot’s shape.&lt;/p&gt;

&lt;p&gt;What’s &lt;em&gt;actually&lt;/em&gt; happening in the physical world is complicated here. There are elastic elements interacting with (potentially) other elastic elements in complex ways. There is difficult-to-model friction between components of the robot, hysteresis, potentially difficult-to-predict material properties, etc.&lt;/p&gt;

&lt;p&gt;The continuum robotics community has taken a variety of approaches to modeling, but a fundamental trend exists: a &lt;strong&gt;trade-off between accuracy and speed-of-computation&lt;/strong&gt;. That is, models which may be fast to compute are typically fast because they neglect to account for some of the physical phenomenon present in the actual robot. On the flip side, models that account for those phenomenon are slow to compute. In reality, there’s a spectrum here.&lt;/p&gt;

&lt;p&gt;Constant curvature models, for instance, may take a purely geometric approach to FK, which is fast to compute, but tend to be less accurate. On the other end of the spectrum, you could consider leveraging something like finite element analysis to simulate the physics of a continuum robot to compute its shape. This would improve accuracy but would be much, much slower to compute. Somewhere in the middle of these you may find things like the Cosserat rod/string models, which are a popular way to model continuum robots and will be discussed in other blog posts here (this is the approach we take in my lab, usually, when we aren’t using machine learning-based methods).&lt;/p&gt;

&lt;p&gt;Let’s contrast this with serial-link manipulator arms. For these, FK typically require only the multiplication of a handful of matrices, which is comparatively VERY fast, and comparatively VERY accurate, as these robots are rigid.&lt;/p&gt;

&lt;p&gt;Okay, so why is this a problem when performing motion planning for continuum robots?&lt;/p&gt;

&lt;p&gt;Well, one way to think about motion planning is that we are reasoning &lt;em&gt;in advance of actually moving&lt;/em&gt; about the best way to move the robot to achieve our goals. This means that we need our ability to reason about motion to be accurate, otherwise how we predict the robot will move doesn’t mean much. For this reason, model inaccuracy plays havoc with naïve motion planning methods (such as we’ve discussed in last week’s &lt;a href=&quot;/opencontinuumrobotics/101/2023/06/23/intro-mp-part1.html&quot;&gt;post&lt;/a&gt;), and continuum robots have inaccurate models.&lt;/p&gt;

&lt;p&gt;Further, the ways in which we are reasoning in advance about moving require us to consider a &lt;em&gt;whole bunch of potential motions&lt;/em&gt; for the robot. Every vertex in the grid/lattice-based and sampling-based methods represents an FK computation. Every edge between them requires multiple (often many) FK computations. In the optimization-based methods, the computation of objective and constraint gradients frequently require many FK computations. So the time it takes to compute FK has HUGE implications in motion planning.&lt;/p&gt;

&lt;p&gt;This modeling tension, fast but inaccurate or (somewhat) accurate but slow, is one of the fundamental challenges of applying motion planning to continuum robots, and the one I’ll focus on for the rest of this post.&lt;/p&gt;

&lt;figure class=&quot;&quot;&gt;
  &lt;img src=&quot;/opencontinuumrobotics/assets/images/posts/101-motion-planning-intro-part2-Fig1.png&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;
      As continuum robot models become more accurate, they tend to take longer to compute. This represents one of the fundamental challenges associated with applying motion planning to continuum robots.

    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 id=&quot;how-has-the-community-overcome-these-challenges&quot;&gt;How has the community overcome these challenges?&lt;/h2&gt;

&lt;h3 id=&quot;modeling-accuracy-or-lack-thereof&quot;&gt;Modeling accuracy (or lack thereof)&lt;/h3&gt;
&lt;p&gt;The continuum robotics community (myself included) has largely taken an extremely unsatisfying approach to overcoming modeling inaccuracy. This approach, also used by much of the non-continuum robotics planning world, boils down to a simple idea: don’t let the robot get close to things. That way, if the model is inaccurate, hopefully the robot is far enough away from its environment that it won’t collide with it in unexpected ways.&lt;/p&gt;

&lt;p&gt;As an example, in one of my papers&lt;sup id=&quot;fnref:15&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:15&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;, we build into the objective function a notion of distance from obstacles. Specifically, We  define the cost of a configuration $\boldsymbol{q}$ as:&lt;/p&gt;

\[\begin{split}
    &amp;amp;\texttt{cost}(\boldsymbol{q})=\left\{
    \begin{array}{rcl}
    \cfrac{1}{\texttt{clear}(\boldsymbol{q})},&amp;amp;&amp;amp;\texttt{clear}(\boldsymbol{q}) &amp;gt; 0\\
    \infty,&amp;amp;&amp;amp;\texttt{clear}(\boldsymbol{q}) \le 0,
    \end{array}\right.
  \end{split}\]

&lt;p&gt;where $\texttt{clear}$ is, informally defined here, the signed distance from the robot’s body at that configuration to the nearest obstacle.&lt;/p&gt;

&lt;p&gt;The cost of a path $\boldsymbol{\xi}$ then becomes
\(\texttt{Cost}(\boldsymbol{\xi}) = \int_0^1 \texttt{cost}(\boldsymbol{\xi}(s))ds .\)&lt;/p&gt;

&lt;p&gt;where $s$ is a normalized path arclength parameter. Note here that I’ve used little ‘c’ cost for cost over configuration and big ‘C’ Cost for cost over a path. Creative, I know.&lt;/p&gt;

&lt;p&gt;You should really read the paper if you want formality here, but this should give you the gist. Also note that in the paper the notation is slightly different, but I’ve changed it here to more-closely match what I’ve used in the last &lt;a href=&quot;/opencontinuumrobotics/101/2023/06/23/intro-mp-part1.html&quot;&gt;post&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In that method, we leverage both sampling-based motion planning and optimization-based motion planning in parallel (building on [13]), where the method attempts to minimize the $\texttt{cost}$ of a path. This results in paths that travel as far from obstacles as possible, while still being constrained at the start and end configurations.&lt;/p&gt;

&lt;h3 id=&quot;computation-speed-or-lack-thereof&quot;&gt;Computation speed (or lack thereof)&lt;/h3&gt;
&lt;p&gt;The community has taken a variety of approaches to overcome the slow computation speed of continuum robot mechanical models. Here are a few, with some examples.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The first, and most obvious, is the use of a fast-but-inaccurate mechanical model:&lt;/strong&gt;
For instance, in Lyons et al. &lt;sup id=&quot;fnref:16&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:16&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;, the authors simplify the mechanical model of concentric tube robots in two key ways. First, they assume that the tubes are torsionally rigid. Second, they assume that the stiffness of each tube dominates all of the tubes nested inside of it. This means that the shape of a tube is assumed to be independent of the motions of the tubes internal to it and that each tube deploys in a constant-curvature circular shape. The mechanical model that leverages these assumptions is sufficiently fast for planning, but again as discussed above &lt;em&gt;ad nauseam&lt;/em&gt;, comes at the significant cost of accuracy.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Another approach is to lean on advances in software engineering and programming languages to speed up the computation:&lt;/strong&gt;
Leibrandt et. al.&lt;sup id=&quot;fnref:17&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:17&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; leverage &lt;a href=&quot;https://en.wikipedia.org/wiki/Template_metaprogramming&quot;&gt;template metaprogramming in C++&lt;/a&gt;, which (I’m oversimplifying this explanation) moves a lot of expensive run-time computation to compile-time computation for concentric tube robots. This enabled very fast kinematics computation. The method leverages this in a PRM-style motion planner. In our paper&lt;sup id=&quot;fnref:15:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:15&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; mentioned above, we use this template-based kinematic model, wrapping our parallel sampling and optimization method around it. Speaking of, our&lt;sup id=&quot;fnref:15:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:15&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; use of &lt;a href=&quot;https://en.wikipedia.org/wiki/Parallel_computing&quot;&gt;parallelism&lt;/a&gt; is another example of leveraging software engineering concepts to speed up computation in planning for continuum robots.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;We can also consider leveraging precomputation:&lt;/strong&gt;
In the paper &lt;sup id=&quot;fnref:18&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:18&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt; (its extension &lt;sup id=&quot;fnref:19&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:19&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;), the authors propose leveraging precomputation to build a roadmap for planning &lt;em&gt;after the environment is known but in advance of when it is needed&lt;/em&gt;. This is a pretty specific (and restrictive) scenario, but makes sense in the application put forth by the papers, namely in surgery. These works present the case that pre-operative medical imaging provides the method with a 3D environment a day (or more) prior to when the surgery will happen. The method can then leverage that time to compute a dense, collision-free roadmap before it’s needed at surgery time. The proposed method utilizes the sampling-based method Rapidly-exploring Random Graph (RRG) (which is also presented in &lt;sup id=&quot;fnref:7&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:7&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;, in addition to PRM* and RRT*). The method also utilizes one of, if not the most precise (at the time, at least) mechanical models available for concentric tube robots. This dense, collision-free roadmap is built over the course of many hours using this accurate model and the anatomical environment segmented from the pre-operative medical imaging. Then, at the time of the surgery, the method proposes an interactive-rate supervisory control-style scheme in which a haptic device is used by the surgeon to input a desired tip position for the robot in the patient. Leveraging a nearest-neighbor data structure, the vertex in the roadmap that corresponds to the configuration with the robot’s tip closest to the desired position is then identified. Graph search is performed to identify a path on the roadmap from the current configuration to that configuration, and then the method “steps off” of the roadmap and leveraging damped least-squares iterative inverse kinematics &lt;sup id=&quot;fnref:20&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:20&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&quot;fnref:21&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:21&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt;, which is conceptually very similar to resolved-rates control, drives the tip of the robot as close to the desired tip position as it can. This then repeats in a loop.&lt;/p&gt;

&lt;p&gt;In our paper&lt;sup id=&quot;fnref:22&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:22&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;9&lt;/a&gt;&lt;/sup&gt;, my group has built upon this concept in a few ways. Among other contributions, we adapt the concepts to work for tendon-driven continuum robots (&lt;sup id=&quot;fnref:18:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:18&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt; and &lt;sup id=&quot;fnref:19:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:19&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt; are specific to concentric tube robots), introduce a modification to mechanical modeling and collision detection to improve speed, and remove the need to have the environment in advance of precomputing the dense roadmap. The method still heavily leverages precomputation, but only requires the environment immediately prior to when the supervisory control loop is started.&lt;/p&gt;

&lt;h2 id=&quot;so-whats-next&quot;&gt;So what’s next?&lt;/h2&gt;
&lt;p&gt;What are the open problems or areas to be explored in motion planning for continuum robots? Here are a few that I’m personally excited about.&lt;/p&gt;
&lt;h3 id=&quot;leveraging-learned-models-in-planning&quot;&gt;Leveraging learned models in planning&lt;/h3&gt;
&lt;p&gt;There has recently been a large interest in machine learning-based mechanical models of continuum robots, both for their potential to learn unmodeled (or unknowable/unmodelable) effects and their potential for fast computation (e.g., frequently the shape computation of a learned model is faster than the physics-based equivalent). I’ll leave the details of these methods to another post, written by myself or someone else. However germane to THIS post, how to leverage these types of models for motion planning of continuum robots is as-yet underexplored.&lt;/p&gt;

&lt;h3 id=&quot;principled-planning-under-uncertainty&quot;&gt;Principled planning under uncertainty&lt;/h3&gt;
&lt;p&gt;Motion planning in a way that handles uncertainty in a principled way has been leveraged to great effect in other areas of robotics. Given the uncertainty associated with continuum robots, the application/exploration of using these types of methods/formulations in planning for continuum robots has great potential.&lt;/p&gt;

&lt;h3 id=&quot;multi-fidelity-planning&quot;&gt;Multi-fidelity planning&lt;/h3&gt;
&lt;p&gt;The fact that we have a variety of models for continuum robots that trade computation speed for accuracy implies exciting potential for the use of multi-fidelity planning. One can imagine, as maybe the most obvious example, using a fast but inaccurate model to prioritize edge evaluation in a lazy planning paradigm, look up Lazy PRM if that doesn’t make sense to you, where full edge evaluation is then done with a high-fidelity model.&lt;/p&gt;

&lt;h2 id=&quot;closing-remarks&quot;&gt;Closing remarks&lt;/h2&gt;
&lt;p&gt;Hopefully the above alongside last week’s &lt;a href=&quot;/opencontinuumrobotics/101/2023/06/23/intro-mp-part1.html&quot;&gt;Part 1&lt;/a&gt; were a relatively gentle introduction to motion planning and how it relates conceptually to continuum robots. This wasn’t intended to be a comprehensive survey of planning for continuum robots. Rather, my intention was to give you the vocabulary and an understanding of the rough concepts sufficient for you to investigate the rest of the literature yourself, and to innovate on the state-of-the-art as you need for your specific problems.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:15&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;A. Kuntz, M. Fu, R. Alterovitz: Planning High-Quality Motions for Concentric Tube Robots in Point Clouds via Parallel Sampling and optimization. IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 2205-2212, 2019. doi: &lt;a href=&quot;https://doi.org/10.1109/IROS40897.2019.8968172&quot;&gt;10.1109/IROS40897.2019.8968172&lt;/a&gt; &lt;a href=&quot;#fnref:15&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:15:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; &lt;a href=&quot;#fnref:15:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:16&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;L. A. Lyons, R. J. Webster, R. Alterovitz: Motion planning for active cannulas. IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 801-806, 2009. doi: &lt;a href=&quot;https://doi.org/10.1109/IROS.2009.5354249&quot;&gt;10.1109/IROS.2009.5354249&lt;/a&gt; &lt;a href=&quot;#fnref:16&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:17&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;K. Leibrandt, C. Bergeles, G.-Z. Yang: Concentric Tube Robots: Rapid, Stable Path-Planning and Guidance for Surgical Use. IEEE Robotics &amp;amp; Automation Magazine, vol. 24, no. 2, pp. 42-53, 2017. doi: &lt;a href=&quot;https://doi.org/10.1109/MRA.2017.2680546&quot;&gt;10.1109/MRA.2017.2680546&lt;/a&gt; &lt;a href=&quot;#fnref:17&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:18&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;L. G. Torres, C. Baykal,  R. Alterovitz: Interactive-rate motion planning for concentric tube robots. IEEE International Conference on Robotics and Automation (ICRA), pp. 1915-1921, 2014. doi: &lt;a href=&quot;https://doi.org/10.1109/ICRA.2014.6907112&quot;&gt;10.1109/ICRA.2014.6907112&lt;/a&gt; &lt;a href=&quot;#fnref:18&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:18:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:19&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;L. G. Torres et al.: A motion planning approach to automatic obstacle avoidance during concentric tube robot teleoperation. IEEE International Conference on Robotics and Automation (ICRA), pp. 2361-2367, 2015. doi: &lt;a href=&quot;https://doi.org/10.1109/ICRA.2015.7139513&quot;&gt;10.1109/ICRA.2015.7139513&lt;/a&gt; &lt;a href=&quot;#fnref:19&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:19:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:7&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;S. Karaman and E. Frazzoli: Sampling-based algorithms for optimal motion planning. The International Journal of Robotics Research, 30(7):846-894, 2011. doi: &lt;a href=&quot;https://doi.org/10.1177/0278364911406761&quot;&gt;10.1177/0278364911406761&lt;/a&gt; &lt;a href=&quot;#fnref:7&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:20&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Y. Nakamura and H. Hanafusa: Inverse Kinematic Solutions With Singularity Robustness for Robot Manipulator Control. ASME. J. Dyn. Sys., Meas., Control., 108(3):163–171, 1986. doi: &lt;a href=&quot;https://doi.org/10.1115/1.3143764&quot;&gt;10.1115/1.3143764&lt;/a&gt; &lt;a href=&quot;#fnref:20&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:21&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;C. W. Wampler: Manipulator Inverse Kinematic Solutions Based on Vector Formulations and Damped Least-Squares Methods. IEEE Transactions on Systems, Man, and Cybernetics, 16(1):93-101, 1986. doi: &lt;a href=&quot;https://doi.org/10.1109/TSMC.1986.289285&quot;&gt;10.1109/TSMC.1986.289285&lt;/a&gt; &lt;a href=&quot;#fnref:21&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:22&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;M. Bentley, C. Rucker, A. Kuntz: Interactive-Rate Supervisory Control for Arbitrarily-Routed Multitendon Robots via Motion Planning. IEEE Access, vol. 10, pp. 80999-81019, 2022. doi: &lt;a href=&quot;https://doi.org/10.1109/ACCESS.2022.3194515&quot;&gt;10.1109/ACCESS.2022.3194515&lt;/a&gt; &lt;a href=&quot;#fnref:22&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Alan Kuntz</name></author><category term="101" /><summary type="html">What makes motion planning particularly challenging for continuum robots? How does the continuum robotics community tackle those challenges?</summary></entry><entry><title type="html">Introduction to Motion Planning for Continuum Robots - Part 1</title><link href="https://continuumroboticslab.github.io/opencontinuumrobotics/101/2023/06/23/intro-mp-part1.html" rel="alternate" type="text/html" title="Introduction to Motion Planning for Continuum Robots - Part 1" /><published>2023-06-23T00:00:00-04:00</published><updated>2023-06-23T00:00:00-04:00</updated><id>https://continuumroboticslab.github.io/opencontinuumrobotics/101/2023/06/23/intro-mp-part1</id><content type="html" xml:base="https://continuumroboticslab.github.io/opencontinuumrobotics/101/2023/06/23/intro-mp-part1.html">&lt;p&gt;First though.. &lt;strong&gt;What is motion planning?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Motion planning stands as a central pillar in robotics. Planning enables robots and autonomous agents to move themselves and other parts of the world to a desired goal by choosing a sequence of appropriate actions. Like robotics in general, motion planning draws on a number of different fields in developing its tools. Approaches to motion planning have grown out of artificial intelligence, optimal control, and operations research.&lt;/p&gt;

&lt;p&gt;That’s the first paragraph of my motion planning course syllabus. It’s a bit… grandiose, but I’ve found it to be effective in convincing the students that they are about to learn something interesting; hopefully it worked on you as well. It was also written by the professor who taught the course before I did, and whose syllabus I used as a starting point for my own (on the shoulders of giants etc etc etc). If that was sufficiently dramatic and you’re convinced to keep reading, let’s get to it.&lt;/p&gt;

&lt;p&gt;More colloquially, motion planning can be broadly defined as the problem of computing motions, actions, or controls that move a robot through its environment in such a way that some task is performed while obeying some set of constraints.&lt;/p&gt;

&lt;p&gt;In its most basic form, that task can be defined as moving from some start configuration to some goal configuration, with typical constraints being defined as obstacle avoidance over the motion, obeying joint limits, etc. Complexity in task definitions and constraint definitions builds from there.&lt;/p&gt;

&lt;p&gt;I personally like to present motion planning as a generic optimization problem and then look specifically at how aspects of that problem are defined. &lt;strong&gt;Be forewarned, I’m going to grossly abuse notation/terminology and ignore nuance all over this post with the goal of imparting intuition rather than specifics.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Consider:&lt;/p&gt;

&lt;p&gt;$\boldsymbol{\xi}^* = \underset{\boldsymbol{\xi}}{\texttt{argmin}}\  \texttt{cost}(\boldsymbol{\xi})$&lt;/p&gt;

&lt;p&gt;$s.t. \ \ \ c(\boldsymbol{\xi}) \ge 0$
$\ \ \ \ \ \ \ \ d(\boldsymbol{\xi}) = 0$&lt;/p&gt;

&lt;p&gt;where $\boldsymbol{\xi}$ represents some trajectory, path, or plan parameterization, $\texttt{cost}$ is some cost function defined over these, $\boldsymbol{\xi}^*$ is an optimal plan under the cost function, and $c$ and $d$ are generic, as-of-yet-unspecified inequality and equality constraints (or sets of such constraints).&lt;/p&gt;

&lt;p&gt;This generic optimization formalization is sufficiently expressive to talk about most of the basics of motion planning, and by varying how aspects of this formalization are defined we can arrive at most of the ways people have historically thought about motion planning.&lt;/p&gt;

&lt;p&gt;As an example, let’s consider the very simple (relative to other motion planning problems) task of moving a holonomic robot from some start state to some goal state while avoiding some set of obstacles in its environment.&lt;/p&gt;

&lt;p&gt;If we conceptualize $\boldsymbol{\xi}$ as defining a space curve in the robot’s configuration space, we can parameterize $\boldsymbol{\xi}$ by the normalized path length such that $\boldsymbol{\xi}(0)$ is the robot’s start configuration and $\boldsymbol{\xi}(1)$ is the robot’s configuration after following the full plan.&lt;/p&gt;

&lt;p&gt;Often people consider minimizing path length, so we can imagine defining $\texttt{cost}$ as the length of the path (under some appropriate definition of length).&lt;/p&gt;

&lt;p&gt;We also want to &lt;em&gt;constrain&lt;/em&gt; the trajectory such that the robot ends in a goal configuration (broadly as an element of some goal set), and such that the entire trajectory avoids obstacles.&lt;/p&gt;

&lt;p&gt;We can then cast this simple problem into our optimization framework simply as:&lt;/p&gt;

&lt;p&gt;$\boldsymbol{\xi}^* = \underset{\boldsymbol{\xi}}{\texttt{argmin}}\  \texttt{length}(\boldsymbol{\xi})$&lt;/p&gt;

&lt;p&gt;$s.t. \ \ \ \boldsymbol{\xi}(0) = \textrm{start configuration}$&lt;/p&gt;

&lt;p&gt;$\ \ \ \ \ \ \ \ \boldsymbol{\xi}(1) \in \textrm{goal set}$&lt;/p&gt;

&lt;p&gt;$\ \ \ \ \ \ \ \ \boldsymbol{\xi}(s) \textrm{ is collision free } \forall s \in [0,1]$&lt;/p&gt;

&lt;p&gt;As in most interesting things, key considerations lie in the details (which I’ve completely ignored above). How is your trajectory parameterized? How do you define your goal set? How do you represent your robot and environment geometry, enabling you to check for collision? Is length even the right objective to minimize? The answer to these questions depends on your specific problem/robot/etc. If I knew what this is for you, I’d just solve your problems myself and take all the credit.&lt;/p&gt;

&lt;p&gt;Okay, so this is the first step—representing your problem. Next, let’s solve it.&lt;/p&gt;

&lt;h2 id=&quot;how-do-methods-typically-work&quot;&gt;How do methods typically work?&lt;/h2&gt;
&lt;p&gt;In my head I broadly group modern motion planning methods into three groups, discrete grid/lattice-based search methods, sampling-based methods, and optimization-based methods. There’s an implied fourth group, “other” or maybe “miscellany”, but I’m going to focus on the first three in this post.&lt;/p&gt;

&lt;figure class=&quot;&quot;&gt;
  &lt;img src=&quot;/opencontinuumrobotics/assets/images/posts/101-motion-planning-intro-part1-Fig1.png&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;
      We can parameterize a robot’s configuration space by its actuation variables. Consider here a (ridiculously over-) simplified case of a single-tube concentric tube robot (which makes it just a tube robot, really, nothing concentric about it). We can actuate this robot by translating it in and out of its rectangular base, and by rotating it. A configuration can then be described as a point in this plane where one axis represents the translational value and one the rotational value. In practice, this space will be higher dimensional. For instance, a two-tube concentric tube robot would probably have a 4-dimensional space, two rotational and two translational, and a three-tube robot a 6-dimensional space, etc. It is in this space, which you can think about as the parameterized configuration space, that motion planning frequently happens.

    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 id=&quot;discrete-gridlattice-based-search-methods&quot;&gt;Discrete grid/lattice-based search methods&lt;/h2&gt;
&lt;p&gt;At their simplest, these methods consider a graph or tree (which is just a special kind of graph) embedded in the robot’s configuration space. If you are unsure what I mean by “graph or tree” stop now and read &lt;a href=&quot;https://en.wikipedia.org/wiki/Graph_%28abstract_data_type%29&quot;&gt;this&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Tree_%28data_structure%29&quot;&gt;this&lt;/a&gt; before moving on.&lt;/p&gt;

&lt;p&gt;Notably for these methods, the graph is usually implied by a &lt;em&gt;discretization&lt;/em&gt; over the robot’s possible actions. Imagine vertices of the graph as representing configurations or states of the robot, and edges as actions between states, which when applied from the source state result in the robot transitioning to the destination state. This action discretization is frequently defined in advance (and you can imagine applying this concept to robot’s with continuous action spaces simply by discretizing those action spaces). Due to the constant discretization, you can conceptualize these as creating something like a grid or lattice as the graph.&lt;/p&gt;

&lt;p&gt;With this conceptualization, motion planning then reduces to a &lt;em&gt;search&lt;/em&gt; over that graph, seeking the “shortest” path from your start vertex to any vertex that represents a goal configuration or state.&lt;/p&gt;

&lt;figure class=&quot;&quot;&gt;
  &lt;img src=&quot;/opencontinuumrobotics/assets/images/posts/101-motion-planning-intro-part1-Fig2.png&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;
      In the discrete grid/lattice-based search methods, we can conceptualize something like this grid-shaped graph embedded in the configuration space. Some of this graph may correspond to configurations where the robot’s shape collides with obstacles, such as this red volume which represents configurations where the tube is colliding with that liver there. (It’s a liver. Don’t ask me where it came from, I don’t make the rules. Regardless, we don’t want to run into it with our robot). If we have a start and goal configuration that are on this graph, or that we can easily connect to this graph, then we can run a graph search algorithm on this graph which, if we do it correctly, will return for us a collision free path (shown here in pink). Note: In these figures I’ve drawn a configuration space obstacle that corresponds to the liver obstacle in the robot’s workspace. This is just an example. This drawing is NOT what the configuration space obstacle would actually look like. In fact, in general it is infeasible to fully describe the configuration space obstacles. Many of the motion planning methods I describe here were designed in part to overcome this very issue.

    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;How does this map back to our optimization formalization above? The cost function is minimized by applying a graph-search method that minimizes the accumulation of edge cost (so you need to define a cost over edges and recognize that without substantial modification you’re limited to considering objectives that can be modeled by costs that accumulate). The constraints are enforced simply by not considering edges that would result in a violation of the constraints during the search.&lt;/p&gt;

&lt;p&gt;Cannonical graph search methods (not specific to motion plannning) include &lt;a href=&quot;https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm#Practical_optimizations_and_infinite_graphs&quot;&gt;Uniform Cost Search (UCS)&lt;/a&gt; (closely related to &lt;a href=&quot;https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm&quot;&gt;Djikstra’s algorithm&lt;/a&gt;) and &lt;a href=&quot;https://en.wikipedia.org/wiki/A*_search_algorithm&quot;&gt;A* search&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The key to applying these methods in motion planning is frequently in coming up with an effective and admissible/consistent heuristic (see A* details for what that means). More advanced methods applied to motion planning specifically include D*&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;, D*-Lite&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;, and LPA*&lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;.
It’s also very much worth noting that inadmissible heuristics can also be leveraged to potentially great effect (see Multi-Heuristic A*&lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;).&lt;/p&gt;

&lt;h2 id=&quot;sampling-based-methods&quot;&gt;Sampling-based methods&lt;/h2&gt;
&lt;p&gt;Perhaps the most popular class of motion planning methods, the sampling-based approaches are closely related to the graph-search methods. In fact, these methods frequently leverage graph search but on a graph constructed in a different manner.&lt;/p&gt;

&lt;p&gt;Rather than a graph constructed via a discretization over the robot’s actions, the sampling-based methods leverage &lt;em&gt;random sampling&lt;/em&gt; to construct the graph incrementally (this is why they are called sampling-based, as you may have guessed). The graph (or tree, which again, is just a special kind of graph) is embedded in the robot’s configuration space as above. It is constructed by iteratively randomly sampling states (or actions, sometimes) and attempting to connect the newly sampled state (or state resulting from the sampled action) to the graph/tree.&lt;/p&gt;

&lt;p&gt;When adding states, (usually) the new state and the edge connecting it to the graph are checked for validity (e.g., joint-limit satisfaction and obstacle avoidance). If the state and/or edge are not valid, they aren’t added to the graph.&lt;/p&gt;

&lt;p&gt;At some point, the hope is that the graph will contain a goal state, and then by running graph search (e.g., A*) on this randomly-generated graph the method will find a path from the start state to a goal. If the graph is a tree, this search is trivial as there’s only one path in the graph (ignoring some nuance, that’s what tree means).&lt;/p&gt;

&lt;figure class=&quot;&quot;&gt;
  &lt;img src=&quot;/opencontinuumrobotics/assets/images/posts/101-motion-planning-intro-part1-Fig3.png&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;
      In the sampling-based methods, the graph (or tree) is constructed in the configuration space via random sampling. It will almost certainly have a much different structure than the grid/lattice graphs will, and subsequently the algorithms will exhibit different properties.

    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;The specifics of the graph, how the states/actions are sampled, how the connections are made, etc., are what distinguish the sampling-based methods from each other.&lt;/p&gt;

&lt;p&gt;Okay, so let’s map these concepts back to our optimization formulation.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cost:&lt;/strong&gt; If there are multiple paths in the graph, then the graph search over the graph can provide the lowest cost path in the graph, however the lowest cost path &lt;em&gt;possible&lt;/em&gt; may not be in the graph at any given iteration. Many of the earlier versions of these methods ignored cost and instead attempted to find any path that avoided obstacles, providing a property called probabilistic-completeness. Since then, other methods build upon this to provide a guarantee called asymptotic optimality, which intuitively means that their best path will approach an optimal path (in cost) as runtime progresses (only getting arbitrarily close to an optimal path in the limit though). This contrasts with the discrete grid/lattice-based search methods in that those methods typically only provide a property called resolution completeness/optimality which intuitively means the path is complete or optimal for the resolution of the discretization, but not necessarily in general.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Constraints:&lt;/strong&gt; As with the discrete grid/lattice-based search methods, the sampling-based methods usually encode constraint satisfaction by only considering states/edges in the graph construction or search that satisfy the constraints, including obstacle avoidance.&lt;/p&gt;

&lt;p&gt;Canonical probabilistically-complete methods include Probabilistic Roadmaps (PRM)&lt;sup id=&quot;fnref:5&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt; and Rapidly-exploring Random Trees (RRT)&lt;sup id=&quot;fnref:6&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;. Popular asymptotically-optimal methods include PRM*/RRT*&lt;sup id=&quot;fnref:7&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:7&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt;, Batch-Informed Trees (BIT)&lt;sup id=&quot;fnref:8&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:8&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt;, and Asymptotically-Optimal-RRT (AO-RRT)&lt;sup id=&quot;fnref:9&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:9&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;9&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p class=&quot;notice--danger&quot;&gt;&lt;strong&gt;&lt;em&gt;Super-duper important point!&lt;/em&gt;&lt;/strong&gt; Just because you’re using sampling-based methods does not mean you’re getting probabilistic completeness or asymptotic optimality. There are properties/assumptions you must satisfy in your specific application of these methods that are frequently nuanced, you’ll need to ensure that you satisfy these things. Read the papers detailing these methods for details!&lt;/p&gt;

&lt;h2 id=&quot;optimization-based-methods&quot;&gt;Optimization-based methods&lt;/h2&gt;
&lt;p&gt;Given the formulation we started with, i.e., casting the motion planning problem as constrained optimization, you may be asking yourself: “wait, why don’t we just use optimization methods from, you know, &lt;em&gt;mathematics&lt;/em&gt;, to solve this problem?” Great question! Enter the optimization-based motion planning methods.&lt;/p&gt;

&lt;p&gt;This class of methods leverages nonlinear, constrained optimization methods from the field of optimization itself explicitly to solve the motion planning problem using variations of our above formulation—rather than relying on the graph-search to minimize cost.&lt;/p&gt;

&lt;p&gt;As of now, the majority of these methods (with an exception mentioned below) leverage gradients (and frequently higher-order derivatives) of the objective function and/or of the constraint functions in iterative optimization methods. Think penalty methods, augmented Lagrangian methods, interior point methods, etc. If these concepts are new to you, there is an amazing textbook on the subject by Wright and Nocedal &lt;sup id=&quot;fnref:10&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:10&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;10&lt;/a&gt;&lt;/sup&gt; that is open almost perpetually in my office.&lt;/p&gt;

&lt;p&gt;At a high level there isn’t much more to the story. These methods take exactly the optimization-based formulation above and apply optimization techniques that work directly on such formulations.&lt;/p&gt;

&lt;figure class=&quot;&quot;&gt;
  &lt;img src=&quot;/opencontinuumrobotics/assets/images/posts/101-motion-planning-intro-part1-Fig4.png&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;
      Potentially abandoning the notion of a graph entirely, the optimization-based methods instead frequently parameterize a curve in the configuration space that connects the start and goal. Here that initial parameterization is just an evenly spaced set of configurations in between the start and goal, without consideration of the obstacles. These methods then leverage numerical optimization to minimize an objective while ensuring constraint satisfaction (such as by bringing the path out of regions of the space that collide with obstacles, a process here represented by the blue arrows).

    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;Is it just that easy? Unfortunately, no. The prior paragraph is true at a high level, but the low level is where the details lie. The specific ways in which these methods define cost and their constraint functions such that they work well with the optimization techniques—e.g., ensuring they have gradients that are well-behaved—can make these methods a bit tricky to use in practice. However in many cases they end up working very, very well, which can make it worth the complexity.&lt;/p&gt;

&lt;p&gt;Canonical methods include CHOMP&lt;sup id=&quot;fnref:11&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:11&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;11&lt;/a&gt;&lt;/sup&gt;, which leverages a variation of gradient descent, and TrajOpt&lt;sup id=&quot;fnref:12&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:12&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;12&lt;/a&gt;&lt;/sup&gt; which leverages Sequential Quadratic Programming (SQP). A different method, that is not nearly as popular as those methods, combines sampling-based planning with interior point optimization&lt;sup id=&quot;fnref:13&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:13&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;13&lt;/a&gt;&lt;/sup&gt;. I include it in this list because it was part of yours truly’s PhD work, and so here is a shameless plug.&lt;/p&gt;

&lt;p&gt;There is also a method called Cross-Entropy Motion Planning (CEMP)&lt;sup id=&quot;fnref:14&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:14&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;14&lt;/a&gt;&lt;/sup&gt; that leverages a gradient-free optimization method (the cross-entropy method, as you may have guessed from the name). This is notable because many difficulties one may encounter in leveraging optimization-based methods may come from the gradients, or lack-thereof.&lt;/p&gt;

&lt;p class=&quot;notice--success&quot;&gt;This concludes Part 1 of my introduction to motion planning for continuum robots. In next week’s &lt;a href=&quot;/opencontinuumrobotics/101/2023/06/28/intro-mp-part2.html&quot;&gt;Part 2&lt;/a&gt; we will look at the challenges of motion planning for continuum robots. Stay tuned!&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;A. Stentz: Optimal and Efficient Path Planning for Partially-Known Environments. IEEE International Conference on Robotics and Automation, pp: 3310–3317, 1994. doi: &lt;a href=&quot;https://doi.org/10.1109/ROBOT.1994.351061&quot;&gt;10.1109/ROBOT.1994.351061&lt;/a&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;S. Koenig, M. Likhachev: Fast Replanning for Navigation in Unknown Terrain. Transactions on Robotics, 21(3):354–363, 2005. doi: &lt;a href=&quot;https://doi.org/10.1109%2Ftro.2004.838026&quot;&gt;10.1109/tro.2004.838026&lt;/a&gt; &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;S. Koenig, M. Likhachev, D. Furcy: Lifelong Planning A*. Artificial Intelligence, 155(1–2):93–146, 2004. doi: &lt;a href=&quot;https://doi.org/10.1016/j.artint.2003.12.001&quot;&gt;10.1016/j.artint.2003.12.001&lt;/a&gt; &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;S. Aine, S. Swaminathan, V. Narayanan, V. Hwang, M. Likhachev: Multi-heuristic A*. The International Journal of Robotics Research, 35(1-3): 224-243, 2016. doi: &lt;a href=&quot;https://doi.org/10.1177/0278364915594029&quot;&gt;10.1177/0278364915594029&lt;/a&gt; &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;L.E. Kavraki, P. Svestka, J.C. Latombe, M.H. Overmars: Probabilistic roadmaps for path planning in high-dimensional configuration spaces. IEEE Transactions on Robotics and Automation,  12(4):566-580, 1996. doi: &lt;a href=&quot;https://doi.org/10.1109/70.508439&quot;&gt;10.1109/70.508439&lt;/a&gt; &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;S.M. LaValle and  J.J. Kuffner Jr: Randomized kinodynamic planning. The International Journal of Robotics Research, 20(5):378-400, 2001. doi: &lt;a href=&quot;https://doi.org/10.1177/02783640122067453&quot;&gt;10.1177/02783640122067453&lt;/a&gt; &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:7&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;S. Karaman and E. Frazzoli: Sampling-based algorithms for optimal motion planning. The International Journal of Robotics Research, 30(7):846-894, 2011. doi: &lt;a href=&quot;https://doi.org/10.1177/0278364911406761&quot;&gt;10.1177/0278364911406761&lt;/a&gt; &lt;a href=&quot;#fnref:7&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:8&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;J.D. Gammell, T.D. Barfoot, S.S. Srinivasa: Batch Informed Trees (BIT*): Informed asymptotically optimal anytime search. The International Journal of Robotics Research, 39(5):543-567, 2020. doi: &lt;a href=&quot;https://doi.org/10.1177/0278364919890396&quot;&gt;10.1177/0278364919890396&lt;/a&gt; &lt;a href=&quot;#fnref:8&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:9&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;K. Hauser, Y. Zhou: Asymptotically optimal planning by feasible kinodynamic planning in a state–cost space. IEEE Transactions on Robotics, 32(6):1431-1443, 2016. doi: &lt;a href=&quot;https://doi.org/10.1109/TRO.2016.2602363&quot;&gt;10.1109/TRO.2016.2602363&lt;/a&gt; &lt;a href=&quot;#fnref:9&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:10&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;J. Nocedal and S. Wright: Numerical optimization. Springer-Verlag New York, 2006. doi: &lt;a href=&quot;https://doi.org/10.1007/978-0-387-40065-5&quot;&gt;10.1007/978-0-387-40065-5&lt;/a&gt; &lt;a href=&quot;#fnref:10&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:11&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;M. Zucker, N. Ratliff, A.D. Dragan, M. Pivtoraiko, M. Klingensmith, C.M. Dellin, J.A. Bagnell, S.S. Srinivasa: Chomp: Covariant hamiltonian optimization for motion planning. The International Journal of Robotics Research, 32(9-10):1164-1193, 2013. doi: &lt;a href=&quot;https://doi.org/10.1177/0278364913488805&quot;&gt;10.1177/0278364913488805&lt;/a&gt; &lt;a href=&quot;#fnref:11&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:12&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;J. Schulman, Y. Duan, J. Ho, A. Lee, I. Awwal, H. Bradlow, J. Pan, S. Patil, K. Goldberg, P. Abbeel: Motion planning with sequential convex optimization and convex collision checking. The International Journal of Robotics Research, 33(9):1251-1270, 2014. doi: &lt;a href=&quot;https://doi.org/10.1177/0278364914528132&quot;&gt;10.1177/0278364914528132&lt;/a&gt; &lt;a href=&quot;#fnref:12&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:13&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;A. Kuntz, C. Bowen, R. Alterovitz: Fast anytime motion planning in point clouds by interleaving sampling and interior point optimization. Robotics Research: The 18th International Symposium ISRR, pp. 929-945, 2019. doi: &lt;a href=&quot;https://doi.org/10.1007/978-3-030-28619-4_63&quot;&gt;10.1007/978-3-030-28619-4_63&lt;/a&gt; &lt;a href=&quot;#fnref:13&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:14&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;M. Kobilarov: Cross-entropy motion planning. The International Journal of Robotics Research, 31(7):855-871, 2012. doi: &lt;a href=&quot;https://doi.org/10.1177/0278364912444543&quot;&gt;10.1177/0278364912444543&lt;/a&gt; &lt;a href=&quot;#fnref:14&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Alan Kuntz</name></author><category term="101" /><summary type="html">A quick introduction to motion planning, how to represent the problem, and what methods exist to solve it.</summary></entry><entry><title type="html">Continuum Robots @ICRA23</title><link href="https://continuumroboticslab.github.io/opencontinuumrobotics/research/2023/05/12/icra2023-cr-highlights.html" rel="alternate" type="text/html" title="Continuum Robots @ICRA23" /><published>2023-05-12T00:00:00-04:00</published><updated>2023-05-12T00:00:00-04:00</updated><id>https://continuumroboticslab.github.io/opencontinuumrobotics/research/2023/05/12/icra2023-cr-highlights</id><content type="html" xml:base="https://continuumroboticslab.github.io/opencontinuumrobotics/research/2023/05/12/icra2023-cr-highlights.html">&lt;p&gt;This year’s &lt;a href=&quot;https://www.icra2023.org&quot;&gt;IEEE International Conference on Robotics and Automation&lt;/a&gt; holds a firework of continuum robotics research! Are you getting ready for the conference and creating your itineary? The following presentations, workshops, and papers are on my list this year. You can find the full conference &lt;a href=&quot;https://ras.papercept.net/conferences/conferences/ICRA23/program&quot;&gt;program&lt;/a&gt; online!&lt;/p&gt;

&lt;h2 id=&quot;keynotes&quot;&gt;Keynotes&lt;/h2&gt;
&lt;p&gt;My keynote presentation at this year’s ICRA is all about the &lt;a href=&quot;https://www.opencontinuumrobotics.com&quot;&gt;Open Continuum Robotics Project&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;accelerating-medical-robotics-innovation-with-the-open-continuum-robotics-project&quot;&gt;Accelerating Medical Robotics Innovation with the Open Continuum Robotics Project&lt;/h3&gt;
&lt;p class=&quot;notice&quot;&gt;Tuesday, 17:00 - 18:30 - Healthcare Robotics&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; Jessica Burgner-Kahrs&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; From robotically steered catheters and bronchoscopes to single port flexible instruments, continuum robotics has led to great advances in medical robotics over the past decade. Yet, research findings remain stubbornly difficult to reproduce because continuum robotics hardware and software are not readily available, and no common systems exist. Ultimately this slows the pace of innovation.&lt;/p&gt;

&lt;p&gt;The Open Continuum Robotics Project combines hardware, software, and education with the goal of fostering more collaborative, cost-effective, and reproducible research. This enables rapid prototyping and iterative design, allowing researchers and clinicians to test and refine their ideas more quickly – including in resource-constrained settings. In this way, the Open Continuum Robotics Project accelerates the development of new technologies and treatments in medical robotics.&lt;/p&gt;

&lt;h2 id=&quot;workshop-and-tutorials&quot;&gt;Workshop and Tutorials&lt;/h2&gt;
&lt;p&gt;ICRA 2023 features an incredible rich set of workshops and tutorials this year, which makes it very hard to choose which one to attend (or when to rush from one room to the next #FOMO). The following ones feature aspects of continuum robotics and are worth a look!&lt;/p&gt;

&lt;h3 id=&quot;monday&quot;&gt;Monday&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;MW02: &lt;a href=&quot;https://www.growing-robots.com/&quot;&gt;Soft Growing Robots: From Search-and-Rescue to Intraluminal Interventions&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;MW05: &lt;a href=&quot;https://www.santannapisa.it/en/icra-2023-workshop-small-scale-medical-robots&quot;&gt;Shrinking the Cutting Edge: Making Small-Scale Medical Robots for Humans&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;MW10: &lt;a href=&quot;https://www.origabot.cnrs.fr/workshop-icra-2023/&quot;&gt;Origami-based structures for designing soft robots with new capabilities&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;friday&quot;&gt;Friday&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;FW12: &lt;a href=&quot;https://www.mirmi.tum.de/mirmi/events/icra-2023-workshop/&quot;&gt;Geometric Representations: The Roles of Screw Theory, Lie algebra, &amp;amp; Geometric Algebra&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;FW16: &lt;a href=&quot;https://soft-robotics-workshop.bitbucket.io&quot;&gt;Soft Robotics: Fusing function with structure&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;FW22: &lt;a href=&quot;https://sites.google.com/view/icra2023ws-force-shape/home&quot;&gt;Force and shape perception for surgical instruments and robots&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;FT29: &lt;a href=&quot;http://www.softrobotictoolbox.org&quot;&gt;Towards an accessible soft robotics toolbox and validation test rig&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;talks&quot;&gt;Talks&lt;/h2&gt;
&lt;p&gt;The majority of oral presentations of ICRA 2023 are adressing continuum robot modeling, with a focus on kinetostatics and dynamics using Cosserat theory and optimal control theory. It is fantastic to see a trend towards open toolboxes and knowledge mobilization! There are also some exciting soft continuum robot designs!&lt;/p&gt;

&lt;h3 id=&quot;fea-based-soft-robotic-modeling-simulating-a-soft-actuator-in-sofa-i&quot;&gt;FEA-Based Soft Robotic Modeling: Simulating a Soft-Actuator in SOFA (I)&lt;/h3&gt;
&lt;p class=&quot;notice&quot;&gt;09:50-10:00, Paper TuAT2.9&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Ferrentino, Pasquale; Roels, Ellen; Brancart, Joost; Terryn, Seppe	; Van Assche, Guy; Vanderborght, Bram&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Soft robotics modeling is a research topic that is evolving fast. Many techniques are present in literature but most of them require analytical models with a lot of equations that are time-consuming, hard to resolve, and not so easy to handle. For this reason, the help of a soft mechanics simulator is essential in this field. In fact, this paper presents a tutorial on how to build a soft-robot model using an open-source Finite Element Analysis (FEA) simulator, called SOFA. This software is able to generate a simulation scene from a code written in Python or XML, so it can be used by people that with different fields of competence like mechanical knowledge, knowledge of material properties and programming skills. As a case study, a Python simulation of a cable-driven soft actuator that makes contact with a rigid object is considered. The basic working principles of SOFA required to make a scene are explained step by step. In particular, it shows how to simulate the mechanics and animate the bending behavior of the actuator. Furthermore, it will be shown also how to retrieve and save data from simulation, demonstrating that SOFA can easily adapt to a multi-disciplinary subject as the research in soft-robotics, but also be useful for teaching simulation and programming language principles to engineering students.&lt;/p&gt;

&lt;h3 id=&quot;sorosim-a-matlab-toolbox-for-hybrid-rigid-soft-robots-based-on-the-geometric-variable-strain-approach-i&quot;&gt;SoRoSim: A MATLAB Toolbox for Hybrid Rigid-Soft Robots Based on the Geometric Variable-Strain Approach (I)&lt;/h3&gt;
&lt;p class=&quot;notice&quot;&gt;15:40-15:50, Paper TuBT2.5&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Mathew, Anup Teejo; Ben Hmida, Ikhlas; Armanini, Costanza; Boyer, Frédéric; Renda, Federico&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Soft robotics has been a trending topic within the robotics community for almost two decades. However, available tools for the modeling and analysis of soft robots are still limited. This paper introduces a user-friendly MATLAB toolbox, SoRoSim, that integrates the Geometric Variable Strain model of Cosserat rods to facilitate the static and dynamic analysis of soft, rigid, or hybrid robotic systems. We present a brief overview of the design and structure of the toolbox and validate it by comparing its results with those published in the literature. To highlight the toolbox’s potential to efficiently model, simulate, optimize, and control various robotic systems, we demonstrate four sample applications. The demonstrated applications explore different actuator and external loading conditions of single-, branched-, open-, and closed-chain robotic systems. We think that the soft-robotics research community will significantly benefit from the SoRoSim toolbox for a wide variety of applications.&lt;/p&gt;

&lt;h3 id=&quot;a-geometrically-exact-assumed-strain-modes-approach-for-the-geometrico-and-kinemato-static-modellings-of-continuum-parallel-robots-i&quot;&gt;A Geometrically-Exact Assumed Strain Modes Approach for the Geometrico and Kinemato-Static Modellings of Continuum Parallel Robots (I)&lt;/h3&gt;
&lt;p class=&quot;notice&quot;&gt;15:50-16:00, Paper TuBT2.6&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Briot, Sébastien; Boyer, Frédéric&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; There is a growing interest on the study of continuum parallel robots (CPRs) due to their higher stiffness and better dynamics capacities than serial continuum robots (SCRs). Several works have focused on the computation of their geometrico- and kinemato-static models, that can be sorted into two main categories: (i) models based on the continuous Cosserat equations: They are very accurate but assessing elastic stability with them is tricky; (ii) discretized models: They allow easily checking the elastic stability but they require a large number of elastic variables to be accurate.
In this paper, we extend an approach based on assumed strain modes developed for the dynamics of SCRs to the statics of CPRs. This method is able to predict the robot configuration with an excellent accuracy with a very limited number of elastic variables, contrary to other discretization methods. The method is also more than 100 times faster than finite differences for a better prediction accuracy. Finally, it is possible to assess the robot elastic stability by only checking the Hessian of the potential energy as for any discretization method, thus making the analysis of this property simpler.&lt;/p&gt;

&lt;h3 id=&quot;towards-a-physics-based-model-for-steerable-eversion-growing-robots&quot;&gt;Towards a Physics-Based Model for Steerable Eversion Growing Robots&lt;/h3&gt;
&lt;p class=&quot;notice&quot;&gt;16:00-16:10, Paper TuBT2.7&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Wu, Zicong; De Iturrate Reyzabal, Mikel; Sadati, Seyedmohammadhadi; Liu, Hongbin; Ourselin, Sebastien; Leff, Daniel Richard; Katzschmann, Robert Kevin; Rhode, Kawal; Bergeles, Christos&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Soft robots that grow through eversion/apical extension can effectively navigate fragile environments such as ducts and vessels inside the human body. This letter presents the physics based model of a miniature steerable eversion growing robot. We demonstrate the robot’s growing, steering, stiffening and interaction capabilities. The interaction between two robot-internal components is explored, i.e., a steerable catheter for robot tip orientation, and a growing sheath for robot elongation/retraction. The behavior of the growing robot under different inner pressures and external tip forces is investigated. Simulations are carried out within the SOFA framework. Extensive experimentation with a physical robot setup demonstrates agreement with the simulations. The comparison demonstrates a mean absolute error of 10–20% between simulation and experimental results for curvature values, including catheter-only experiments, sheath-only experiments and full system experiments. To our knowledge, this is the first work to explore physics-based modelling of a tendon-driven steerable eversion growing robot. While our work is motivated by early breast cancer detection through mammary duct inspection and uses our MAMMOBOT robot prototype, our approach is general and relevant to similar growing robots.&lt;/p&gt;

&lt;h3 id=&quot;statics-and-dynamics-of-continuum-robots-based-on-cosserat-rods-and-optimal-control-theories-i&quot;&gt;Statics and Dynamics of Continuum Robots Based on Cosserat Rods and Optimal Control Theories (I)&lt;/h3&gt;
&lt;p class=&quot;notice&quot;&gt;16:20-16:30, Paper TuBT2.9&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Boyer, Frédéric; Lebastard, Vincent; Candelier, Fabien; Renda, Federico; Alamir, Mazen&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; This paper explores the relationship between optimal control and Cosserat beam theory from the perspective of solving the forward and inverse dynamics (and statics as a subcase) of continuous manipulators and snake-like bio-inspired locomotors. By invoking the principle of minimum potential energy, and the Gauss principle of least constraint, it is shown that the quasi-static and dynamic evolution of these robots, are solutions of optimal control problems (OCPs) in the space variable, which can be solved at each step (of loading or time) of a simulation with the shooting method. In addition to offering an alternative viewpoint on several simulation approaches proposed in the recent past, the optimal control viewpoint allows us to improve some of them while providing a better understanding of their numerical properties. The approach and its properties are illustrated through a set of numerical examples validated against a reference simulator.&lt;/p&gt;

&lt;h3 id=&quot;cobra-from-industrial-to-medical-surgery-with-slender-continuum-robots-i&quot;&gt;COBRA: From Industrial to Medical Surgery with Slender Continuum Robots (I)&lt;/h3&gt;
&lt;p class=&quot;notice&quot;&gt;15:00-15:10, Paper WeBT2.1&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Alatorre, David; Robles-Linares, Jose A.; Russo, Matteo; Elbanna, Mohamed A.; Wild, Samuel; Dong, Xin; Mohammad, Abdelkhalick; Kell, James; Norton, Andy; Axinte, Dragos&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; The maintenance of critical industrial components is often hindered by limited access, tortuous passages, and complex geometries. In highly constrained environments, inspection tasks are currently performed with borescopes, but even skilled operators struggle with hard-to-reach targets and the limited mobility prevents in-situ repair when defects are identified. Thanks to an active shape control, snake-like and continuum robots can outperform borescopes for short range inspection as well as enable intervention. However, their actuation technology limits their scalability in length, as longer bodies pose control challenges due to their intrinsically low stiffness and space constraints. To overcome the limitations of both borescopes and continuum robots, we here propose a modular design at their intersection, with both active tendon-driven and passively flexible segments. The main elements of the novel design, including actuation and control interface, are described, and the system is demonstrated in scenarios for aerospace assets, nuclear installations, and robot-assisted surgery.&lt;/p&gt;

&lt;h3 id=&quot;a-generalized-framework-for-concentric-tube-robot-design-using-gradient-based-optimization-i&quot;&gt;A Generalized Framework for Concentric Tube Robot Design Using Gradient-Based Optimization (I)&lt;/h3&gt;
&lt;p class=&quot;notice&quot;&gt;10:10-10:20, Paper ThAT2.8&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Lin, Jui-Te;Girerd, Cedric; Yan, Jiayao; Hwang, John T.; Morimoto, Tania K.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Concentric tube robots (CTRs) show particular promise for minimally invasive surgery due to their inherent compliance and ability to navigate in constrained environments. Due to variations in anatomy among patients and variations in task requirements among procedures, it is necessary to customize the design of these robots on a patient- or population-specific basis. However, the complex kinematics and large design space make the design problem challenging. Here we propose a computational framework that can efficiently optimize a robot design and a motion plan to enable safe navigation through the patient’s anatomy. The current framework is the first fully gradient-based method for CTR design optimization and motion planning, enabling an efficient and scalable solution for simultaneously optimizing continuous variables, even across multiple anatomies. The framework is demonstrated using two clinical examples, laryngoscopy and heart biopsy, where the optimization problems are solved for a single patient and across multiple patients, respectively.&lt;/p&gt;

&lt;h3 id=&quot;magnetic-soft-continuum-robots-with-braided-reinforcement&quot;&gt;Magnetic Soft Continuum Robots with Braided Reinforcement&lt;/h3&gt;
&lt;p class=&quot;notice&quot;&gt;10:20-10:30, Paper ThAT2.9&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Lloyd, Peter Robert; Onaizah, Onaizah; Pittiglio, Giovanni; Chathuranga, Damith Suresh; Chandler, James Henry; Valdastri, Pietro&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Flexible catheters are used in a wide variety of surgical interventions including neurological, pancreatic and cardiovascular. In many cases a lack of dexterity and miniaturization along with excessive stiffness results in large regions of the anatomy being deemed inaccessible. Soft continuum robots have the potential to mitigate these issues. Due to its enormous potential for miniaturization, magnetic actuation is of particular interest in this field. Currently, flexible magnetic catheters often rely on forces of anatomical interaction to generate large deformations during navigation and for soft anatomical structures this could be considered potentially damaging. In this study we demonstrate the insertion of a high aspect ratio, 50 mm long by 2 mm diameter, soft magnetic catheter capable of navigating up to a 180 degree bend without the aid of interactive forces. This magnetic catheter is reinforced with a lengthwise braided structure and its magnetization allows it to shape form along tortuous paths. We demonstrate our innovation in a planar silicone pancreas phantom. We also compare our approach with a mechanically equivalent tip driven magnetic catheter and with an identically magnetized, unreinforced catheter.&lt;/p&gt;

&lt;h3 id=&quot;kinetostatic-modeling-of-tendon-driven-parallel-continuum-robots-i&quot;&gt;Kinetostatic Modeling of Tendon-Driven Parallel Continuum Robots (I)&lt;/h3&gt;
&lt;p class=&quot;notice&quot;&gt;15:00-15:10, Paper ThBT5.1&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Lilge, Sven; Burgner-Kahrs, Jessica&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Tendon-driven parallel continuum robots consist of multiple individual continuous kinematic chains, that are actuated in bending utilizing tendons routed along their backbones. This work derives and proposes a Cosserat rod based kinetostatic modeling framework for such parallel structures that allows for efficiently solving the forward, inverse and velocity kinetostatic problems. Using this model, the kinematic properties such as reachable workspace, singularities, manipulability and compliance of tendon-driven parallel continuum robots are studied in detail. Experiments are conducted using a real robotic prototype to validate the derived modeling approach. Overall, a median pose accuracy of 4.9 mm, corresponding to 3.4% of the continuum robots’ lengths, and 6.2◦ is achieved. The median of the model’s computation time results in 0.51 s on standard computing hardware. Fast computations of below 100 ms can be achieved, if an appropriate initial guess for solving the kinetostatic model is available, making the model suitable for a range of different applications including optimization or control.&lt;/p&gt;

&lt;h2 id=&quot;posters&quot;&gt;Posters&lt;/h2&gt;
&lt;p&gt;The poster presentations at ICRA 2023 cover various aspects of (soft) continuum robots, including design, control, and sensing.&lt;/p&gt;

&lt;h3 id=&quot;a-soft-hybrid-actuated-continuum-robot-based-on-dual-origami-structures&quot;&gt;A Soft Hybrid-Actuated Continuum Robot Based on Dual Origami Structures&lt;/h3&gt;
&lt;p class=&quot;notice&quot;&gt;08:30-10:10, Paper TuPO1S-01.2&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Tao, Jian; Hu, Qiqiang; Luo, Tianzhi; Dong, Erbao&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Soft continuum robots have shown tremendous potential for medical and industrial applications owing to their flexibility and continuous deformability. However, their telescopic and bending capabilities and variable stiffness are still limited. This study proposes a novel origami-inspired soft continuum robot to possess large telescopic and bending capabilities while improving stiffness based on the principle of antagonistic actuation. The soft robot consists of dual origami structures. The inner forms an air chamber actuated by pneumatics, and the outer is controlled by nine tendon-driven actuators. The proposed design uses the advantages of a hybrid actuation to achieve motion and stiffness control. The performance of the soft robot is studied experimentally based on single and three robot modules. Results show that the robot has an excellent stretch ratio and a maximum bending angle of 180°. The robot can also increase stiffness to resist the bending deformation induced by self-weight and loads.&lt;/p&gt;

&lt;h3 id=&quot;image-based-pose-estimation-and-shape-reconstruction-for-robot-manipulators-and-soft-continuum-robots-via-differentiable-rendering&quot;&gt;Image-Based Pose Estimation and Shape Reconstruction for Robot Manipulators and Soft, Continuum Robots Via Differentiable Rendering&lt;/h3&gt;
&lt;p class=&quot;notice&quot;&gt;Tuesday 08:30-10:10, Paper TuPO1S-01.6, Room T8&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Lu, Jingpei; Liu, Fei; Girerd, Cedric; Yip, Michael C.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; State estimation from measured data is crucial for robotic applications as autonomous systems rely on sensors to capture the motion and localize in the 3D world. Among sensors that are designed for measuring a robot’s pose, or for soft robots, their shape, vision sensors are favorable because they are information-rich, easy to set up, and cost-effective. With recent advancements in computer vision, deep learning-based methods no longer require markers for identifying feature points on the robot. However, learning-based methods are data-hungry and hence not suitable for soft and prototyping robots, as building such bench-marking datasets is usually infeasible. In this work, we achieve image-based robot pose estimation and shape reconstruction from camera images. Our method requires no precise robot meshes, but rather utilizes a differentiable renderer and primitive shapes. It hence can be applied to robots for which CAD models might not be available or are crude. Our parameter estimation pipeline is fully differentiable. The robot shape and pose are estimated iteratively by back-propagating the image loss to update the parameters. We demonstrate that our method of using geometrical shape primitives can achieve high accuracy in shape reconstruction for a soft continuum robot and pose estimation for a robot manipulator.&lt;/p&gt;

&lt;h3 id=&quot;discrete-time-model-based-control-of-soft-manipulator-with-fbg-sensing&quot;&gt;Discrete-Time Model Based Control of Soft Manipulator with FBG Sensing&lt;/h3&gt;
&lt;p class=&quot;notice&quot;&gt;08:30-10:10, Paper TuPO1S-01.8&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Franco, Enrico; Aktas, Ayhan; Treratanakulchai, Shen; Garriga-Casanovas, Arnau; Donder, Abdulhamit; Rodriguez y Baena, Ferdinando&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; In this article we investigate the discrete-time model based control of a planar soft continuum manipulator with proprioceptive sensing provided by fiber Bragg gratings. A control algorithm is designed with a discrete-time energy shaping approach which is extended to account for control-related lag of digital nature. A discrete-time nonlinear observer is employed to estimate the uncertain bending stiffness of the manipulator and to compensate constant matched disturbances. Simulations and experiments demonstrate the effectiveness of the controller compared to a continuous time implementation.&lt;/p&gt;

&lt;h3 id=&quot;a-soft-robot-with-three-dimensional-shape-sensing-and-contact-recognition-multi-modal-sensing-via-tunable-soft-optical-sensors&quot;&gt;A Soft Robot with Three Dimensional Shape Sensing and Contact Recognition Multi-Modal Sensing Via Tunable Soft Optical Sensors&lt;/h3&gt;
&lt;p class=&quot;notice&quot;&gt;08:30-10:10, Paper TuPO1S-02.1&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; McCandless, Max; Juliá Wise, Frank; Russo, Sheila&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Soft optical sensing strategies are rapidly developing for soft robotic systems as a means to increase the controllability of soft compliant robots. In this paper, we present a roughness tuning strategy for the fabrication of soft optical sensors to achieve the dual functionality of shape sensing combined with contact recognition within a single multi-modal sensor. The molds used to fabricate the soft sensors are roughened via laser micromachining to achieve asymmetrical sensor responses when bent in opposite directions. We demonstrate the integration of these sensors into a fully soft robotic platform consisting of a multi-directional bending module with integrated 3D shape sensing and a gripper with tip position monitoring along with contact force recognition. We show the accuracy of our sensing strategy in validation experiments and a pick-andplace task is performed to demonstrate the robot’s functionality.&lt;/p&gt;

&lt;h3 id=&quot;on-tendon-driven-continuum-robots-with-compressible-backbones&quot;&gt;On Tendon Driven Continuum Robots with Compressible Backbones&lt;/h3&gt;
&lt;p class=&quot;notice&quot;&gt;08:30-10:10, Paper TuPO1S-03.7&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Srivastava, Manu; Walker, Ian&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; This paper discusses the effect of axial backbone compression on tendon-driven continuum robots. A new mechanics model for compensating for this effect that does not require tendon tension sensing or knowledge of manipulator material properties/stiffnesses is introduced and analyzed. In addition, we provide an analytical expression for the minimum preload on the tendons to achieve a given bend, a quantity determined empirically thus far. Our model is computationally efficient and achieves real time control on low cost hardware. The analysis is supported by experimental results demonstrating significant improvement over kinematics in open loop control of a tendon-driven continuum hose robot.&lt;/p&gt;

&lt;h3 id=&quot;data-driven-estimation-of-forces-along-the-backbone-of-concentric-tube-continuum-robots&quot;&gt;Data-Driven Estimation of Forces Along the Backbone of Concentric Tube Continuum Robots&lt;/h3&gt;
&lt;p class=&quot;notice&quot;&gt;Tuesday 15:00-16:40, Paper TuPO2S-02.6, Room T8&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Donat, Heiko; Mohammadi, Pouya; Steil, Jochen J.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Concentric tube continuum robots (CTCRs) belong to the family of continuum robots with applications in minimally invasive surgeries. Because of this application domain, measuring the external forces along the body of the robot is paramount. CTCRs are made up of thin elastic rods and are intended to be applied inside the human body, where conventional sensor-based measurements are not feasible. Consequently, research is resorting to estimate the forces through geometric, numeric, or optimization methods. However, these methods often suffer from slow convergence. In this paper, we introduce a novel data-driven approach for estimating contact forces along the body of a CTCR that offers an estimation precision comparable to the current state-of-the-art optimization-based approaches, but exhibits nearly two orders of magnitude faster convergence. The proposed method is scalable and exhibits a significant performance in response to a wide range of external forces. The approach was evaluated in simulations and on a real 2-tube CTCR.&lt;/p&gt;

&lt;h3 id=&quot;modeling-of-a-robotic-transcatheter-delivery-system&quot;&gt;Modeling of a Robotic Transcatheter Delivery System&lt;/h3&gt;
&lt;p class=&quot;notice&quot;&gt;09:00-10:40, Paper WePO1S-01.6&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Nayar, Namrata Unnikrishnan; Qi, Ronghuai; Desai, Jaydev P.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Intracardiac transcatheter systems guided by advanced imaging modalities are gaining popularity in treating mitral regurgitation in non-surgical candidates. Robotically steerable transcatheter systems must use model-based control strategies to ensure safer and more effective transcatheter procedures with less trauma while using smaller control gains. In this paper, a 4-DoF robotically steerable tendon-driven robot was fabricated, and the relationship between the tendon displacement and the joint angle was derived. This relation was derived in two parts to make this approach applicable to any other catheter system. A model was derived to determine the tendon tensions needed to achieve desired joint angles. Then, the tendon characteristics were studied, and a tendon elongation (TE) model was derived as a function of tendon length. Executing the modeling process in two steps makes it easy to introduce additional parameters like length, friction, and pose, to characterize complex systems like catheters. The TE model was used to actuate the joints of the robot and RMSE was computed to characterize its performance. Also, PID control was used along with the TE model to improve the system’s performance, and the contribution of the model and the controller in the system was recorded.&lt;/p&gt;

&lt;h3 id=&quot;a-novel-concentric-tube-steerable-drilling-robot-for-minimally-invasive-treatment-of-spinal-tumors-using-cavity-and-u-shape-drilling-techniques&quot;&gt;A Novel Concentric Tube Steerable Drilling Robot for Minimally Invasive Treatment of Spinal Tumors Using Cavity and U-Shape Drilling Techniques&lt;/h3&gt;
&lt;p class=&quot;notice&quot;&gt;09:00-10:40, Paper WePO1S-01.11&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Sharma, Susheela; Park, Ji Hwan; Amadio, Jordan P.; Khadem, Mohsen; Alambeigi, Farshid&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; In this paper, we present the design, fabrication, and evaluation of a novel flexible, yet structurally strong, Concentric Tube Steerable Drilling Robot (CT-SDR) to improve minimally invasive treatment of spinal tumors. Inspired by concentric tube robots, the proposed two degree-of-freedom (DoF) CT-SDR, for the first time, not only allows a surgeon to intuitively and quickly drill smooth planar and out-of-plane J- and U- shape curved trajectories, but it also, enables drilling cavities through a hard tissue in a minimally invasive fashion. We successfully evaluated the performance and efficacy of the proposed CT-SDR in drilling various planar and out-of-plane J-shape branch, U-shape, and cavity drilling scenarios on simulated bone materials.&lt;/p&gt;

&lt;h3 id=&quot;magnetic-ball-chain-robots-for-endoluminal-interventions&quot;&gt;Magnetic Ball Chain Robots for Endoluminal Interventions&lt;/h3&gt;
&lt;p class=&quot;notice&quot;&gt;09:00-10:40, Paper WePO1S-01.12&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Pittiglio, Giovanni; Mencattelli, Margherita; Dupont, Pierre&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; This paper introduces a novel class of hyperredundant robots comprised of chains of permanently magnetized spheres enclosed in a cylindrical polymer skin. With their shape controlled using an externally-applied magnetic field, the spherical joints of these robots enable them to bend to very small radii of curvature. These robots can be used as steerable tips for endoluminal instruments. A kinematic model is derived based on minimizing magnetic and elastic potential energy. Simulation is used to demonstrate the enhanced steerability of these robots in comparison to magnetic soft continuum robots designed using either distributed or lumped magnetic material. Experiments are included to validate the model and to demonstrate the steering capability of ball chain robots in bifurcating channels.&lt;/p&gt;

&lt;h3 id=&quot;model-based-pose-estimation-of-steerable-catheters-under-bi-plane-image-feedback&quot;&gt;Model-Based Pose Estimation of Steerable Catheters under Bi-Plane Image Feedback&lt;/h3&gt;
&lt;p class=&quot;notice&quot;&gt;09:00-10:40, Paper WePO1S-03.2&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Lawson, Jared; Chitale, Rohan; Simaan, Nabil&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Small catheters undergo significant torsional deflections during endovascular interventions. A key challenge in enabling robot control of these catheters is the estimation of their bending planes. This paper considers approaches for estimating these bending planes based on bi-plane image feedback. The proposed approaches attempt to minimize error between either the direct (position-based) or instantaneous (velocity-based) kinematics with the reconstructed kinematics from bi-plane image feedback. A comparison between these methods is carried out on a setup using two cameras in lieu of a bi-plane fluoroscopy setup. The results show that the position-based approach is less susceptible to segmentation noise and works best when the segment is in a non-straight configuration. These results suggest that estimation of the bending planes can be accompanied with errors under 30◦. Considering that the torsional buildup of these catheters can be more than 180◦, we believe that this method can be used for catheter control with improved safety due to the reduction of this uncertainty.&lt;/p&gt;

&lt;h3 id=&quot;image-segmentation-for-continuum-robots-from-a-kinematic-prior&quot;&gt;Image Segmentation for Continuum Robots from a Kinematic Prior&lt;/h3&gt;
&lt;p class=&quot;notice&quot;&gt;09:00-10:40, Paper WePO1S-03.4&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Watson, Connor; Nguyen, Anna; Morimoto, Tania K.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; In this work, we address the problem of robust segmentation of a continuum robot from images without the need for training data or markers. We present a method that leverages information about the kinematics of these robots to produce an estimate of the robot shape, which is refined through optimization over global image statistics. Our approach can be straightforwardly applied to any continuum robot design and is able to handle partial occlusions of the robot body, as well as challenging background conditions. We validate our method experimentally for a concentric tube robot in a simulated surgical environment and show that our method significantly outperforms a naive projection of the robot shape and color thresholding, which is commonly used in current vision-based estimation algorithms for these robots. Overall, this work has the potential to improve the viability of vision-based state estimation for continuum robots in real-world settings.&lt;/p&gt;

&lt;h3 id=&quot;an-equivalent-two-section-method-for-calculating-the-workspace-of-multi-segment-continuum-robots&quot;&gt;An Equivalent Two Section Method for Calculating the Workspace of Multi-Segment Continuum Robots&lt;/h3&gt;
&lt;p class=&quot;notice&quot;&gt;09:00-10:40, Paper ThPO1S-12.4&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Fan, Yeman; Liu, Dikai&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Obtaining the shape and size of a robot’s workspace is essential for both its design and control. However, determining the accurate workspace of a multi-segment continuum robot by graphic or analytical methods is a challenging task due to its inherent flexibility and complex structure. Existing numerical methods have limitations when applied to a continuum robot. This paper presents an Equivalent Two Section (ETS) method for calculating the workspace of multi-segment continuum robots. This method is based on the forward kinematics and a piecewise constant curvature (PCC) model to determine the boundaries of the workspace. In order to verify the proposed method, simulation experiments are conducted using six different maximum bending angles and seven different number of segments. Results of the ETS method are compared to the true workspaces of these configurations estimated by an exhaustive approach. The results show that the proposed ETS method is both efficient and accurate, and has small estimation errors. Discussions on the advantages and limitations of the proposed ETS method are also presented.&lt;/p&gt;

&lt;h3 id=&quot;happarray-haptic-pneumatic-pouch-array-for-feedback-in-hand-held-robots&quot;&gt;HaPPArray: Haptic Pneumatic Pouch Array for Feedback in Hand-Held Robots&lt;/h3&gt;
&lt;p class=&quot;notice&quot;&gt;15:00-16:40, Paper ThPO2S-23.1&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Luo, Xiaolei; Lin, Jui-Te; Morimoto, Tania K.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Haptic feedback can provide operators of hand-held robots with active guidance during challenging tasks and with critical information on environment interactions. Yet for such haptic feedback to be effective, it must be lightweight, capable of integration into a hand-held form factor, and capable of displaying easily discernible cues. We present the design and evaluation of HaPPArray — a haptic pneumatic pouch array — where the pneumatic pouches can be actuated alone or in sequence to provide information to the user. A 3x3 array of pouches was integrated into a handle, representative of an interface for a hand-held robot. When actuated individually, users were able to correctly identify the pouch being actuated with 86% accuracy, and when actuated in sequence, users were able to correctly identify the associated direction cue with 89% accuracy. These results, along with a demonstration of how the direction cues can be used for haptic guidance of a medical robot, suggest that HaPPArray can be an effective approach for providing haptic feedback for hand-held robots.&lt;/p&gt;</content><author><name>Jessica Burgner-Kahrs</name></author><category term="research" /><summary type="html">A curated list of continuum robotics research presented</summary></entry><entry><title type="html">One Actuation Module to Create them All</title><link href="https://continuumroboticslab.github.io/opencontinuumrobotics/hands-on/2023/04/28/one-actuation-module.html" rel="alternate" type="text/html" title="One Actuation Module to Create them All" /><published>2023-04-28T00:00:00-04:00</published><updated>2023-04-28T00:00:00-04:00</updated><id>https://continuumroboticslab.github.io/opencontinuumrobotics/hands-on/2023/04/28/one-actuation-module</id><content type="html" xml:base="https://continuumroboticslab.github.io/opencontinuumrobotics/hands-on/2023/04/28/one-actuation-module.html">&lt;p&gt;We are excited to announce that our open continuum robotics hardware is now out. It has been a humbling long journey that lead to our manuscript (which is now in review but available as pre-print on arXiv&lt;sup id=&quot;fnref:arXiv2023&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:arXiv2023&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;). To increase the reproducibility and accessibility of continuum robotics research, we release the hardware design, component lists, assembly instructions, and software open source here on our website.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://continuumroboticslab.github.io/opencontinuumrobotics/assets/images/posts/hands-on/one-module-teaser.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As you are reading this on our blog, you are already aware of our initiative called the OpenCR Project. With this week’s post, we are releasing our open actuation module &lt;sup id=&quot;fnref:arXiv2023:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:arXiv2023&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; for the continuum robotics community to build torque-controlled continuum robots. The actuation module is capable of measuring the external torque as demonstrated with very simplified toy examples. Its versatile and modular characteristics are highlighted by building three different types of continuum robot prototypes. The presented prototypes are capable of torque control and fast trajectory tracking making them the first of a kind of the respective continuum robot type.&lt;/p&gt;

&lt;h2 id=&quot;the-why&quot;&gt;The Why&lt;/h2&gt;
&lt;p&gt;Stepping aside, what problem are we actually addressing? In short – the lack of torque-controlled continuum robot prototypes available to all researchers. In fact, this lack is grounded on two observations we made by observing our research community and relating to other research areas in robotics.&lt;/p&gt;

&lt;p&gt;First, in our previous study &lt;sup id=&quot;fnref:WS_RSS_2020&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:WS_RSS_2020&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;, we observed that precious time and focus are devoted to building custom prototypes. One can acknowledge that experiments on physical hardware in robotics are necessary and valuable for evaluations. However, over 60% of all prototypes are used for only a single publication. This demonstrates an inefficient habit of not reusing existing prototypes. Thus, a significant amount of time is devoted to creating proprietary hardware and software. This large and growing number of &lt;strong&gt;&lt;em&gt;single-use prototypes&lt;/em&gt;&lt;/strong&gt; imposes a barrier for the research community shifting away time and efforts from important research questions.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://continuumroboticslab.github.io/opencontinuumrobotics/assets/images/posts/hands-on/reused_robot_over_time.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Second, on a more personal note, having the opportunity &lt;sup id=&quot;fnref:RoboterFabrik&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:RoboterFabrik&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;, &lt;sup id=&quot;fnref:TeachingLab&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:TeachingLab&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt; to regularly work with torque-controlled manipulators such as the Franka Emika Panda&lt;sup id=&quot;fnref:16&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:16&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;, utilizing torque control for continuum robots seems to be a natural next stepping stone. Torque control has a rich history, especially for serial kinematic mechanisms &lt;sup id=&quot;fnref:13&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:13&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&quot;fnref:14&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:14&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&quot;fnref:15&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:15&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&quot;fnref:16:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:16&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;. However, for some reason, the spread and success of torque-control used in pHRI (physical human-robot interaction) research has not reached our continuum robotics community. Perhaps, one reason is that not much time has been directed to build a continuum robot prototype capable of torque control.&lt;/p&gt;

&lt;h2 id=&quot;the-opencr-actuation-module&quot;&gt;The OpenCR Actuation Module&lt;/h2&gt;
&lt;p&gt;To provide torque-controlled continuum robot prototypes, we propose a modular actuation module consisting of a high-torque brushless electric motor, a high-resolution optical encoder, and a low-gear-ratio transmission. This choice of hardware allows for torque control and fast trajectory tracking in real time. Furthermore, it enables proprioceptive torque sensing by measuring motor currents without relying on additional sensors, e.g., tension sensors or load cells. In addition, the actuation module and its coupling system can be used in different actuation modes for a wide range of continuum robots. For instance, tendon displacement/tension and backbone rotation/torque can be controlled and measured.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://continuumroboticslab.github.io/opencontinuumrobotics/assets/images/posts/hands-on/one-module-assembly.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Recapping the technological trend towards torque-controlled robot systems in other research fields, we are forecasting a likely impact of the proposed actuation module and continuum robot prototypes built on it. The manuscript &lt;sup id=&quot;fnref:arXiv2023:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:arXiv2023&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; takes initial steps towards advanced control methodologies. We are confident that the ability of continuum robots utilizing our actuation module (or one with similar capabilities) has a decisive advantage over previous existing prototypes. For example, a CTCR can detect external disturbance as shown here:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://continuumroboticslab.github.io/opencontinuumrobotics/assets/images/posts/hands-on/one-module-ctcr-snap.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;one-actuation-module-to-create-them-all&quot;&gt;One Actuation Module to Create them All&lt;/h2&gt;
&lt;p&gt;The actuation module is modular and as such allows you to build any (!?) continuum robot. In the nature of the OpenCR project, we build three different types of continuum robots – a parallel CR, a spatial TDCR, and a CTCR. The image below shows renderings and respective prototypes. By providing open-source hardware and software, we hope that this minimizes the repetitive tasks of developing prototypes, allowing researchers worldwide to focus on the main research challenges in continuum robotics. As a welcome side effect, robot-based evaluations can be performed quickly and become reproducible by other groups!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://continuumroboticslab.github.io/opencontinuumrobotics/assets/images/posts/hands-on/one-module-create-all.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To improve our prototypes, we took great inspiration from the Open Dynamic Robot Initiative, where efforts are made to build cost-efficient actuators for torque-controlled legged robots &lt;sup id=&quot;fnref:12&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:12&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;9&lt;/a&gt;&lt;/sup&gt; and manipulators &lt;sup id=&quot;fnref:6&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;10&lt;/a&gt;&lt;/sup&gt;. As a matter of fact, open robot hardware projects proliferate progress in robotics &lt;sup id=&quot;fnref:RAM_Survey_2023&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:RAM_Survey_2023&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;11&lt;/a&gt;&lt;/sup&gt;. Therefore, we encourage you – dear reader – to participate in the development of open-source software and hardware as well as to join the journey of leveraging torque-controlled prototypes. Let’s pave the way with new stepping stones toward untapped or under-investigated research directions.&lt;/p&gt;

&lt;p&gt;We hope that the open source nature will bear fruit by opening untapped or under-investigated research directions related to dynamics and advanced control of continuum robots.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/2304.11850.pdf&quot; class=&quot;btn btn--info&quot;&gt;Paper&lt;/a&gt; 
&lt;a href=&quot;https://github.com/ContinuumRoboticsLab/OpenCR-Hardware&quot; class=&quot;btn btn--danger&quot;&gt;GitHub&lt;/a&gt; 
&lt;a href=&quot;https://youtu.be/0MefE64Gw0U&quot; class=&quot;btn btn--success&quot;&gt;Video&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:arXiv2023&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Reinhard M. Grassmann, Chengnan Shentu, Taqi Hamoda, Puspita Triana Dewi, Jessica Burgner-Kahrs. “Open Continuum Robotics – One Actuation Module to Create them All,” 2023, arXiv: &lt;a href=&quot;https://arxiv.org/abs/2304.11850&quot;&gt;2304.11850&lt;/a&gt; &lt;a href=&quot;#fnref:arXiv2023&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:arXiv2023:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; &lt;a href=&quot;#fnref:arXiv2023:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:WS_RSS_2020&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;R. M. Grassmann, S. Lilge, P. Le, and J. Burgner-Kahrs, “CTCR prototype development: An obstacle in the research community?” in Robotics Retrospectives Workshop at RSS, 2020. &lt;a href=&quot;https://openreview.net/forum?id=bYLFxFQPFtX&quot;&gt;Online&lt;/a&gt; &lt;a href=&quot;#fnref:WS_RSS_2020&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:RoboterFabrik&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Sami Haddadin, Lars Johannsmeier, Johannes Schmid, Tobias Ende, Sven Parusel, Simon Haddadin, Moritz Schappler, Torsten Lilge, and Marvin Becker. “roboterfabrik: A pilot to link and unify german robotics education to match industrial and societal demands.” International Conference on Robotics and Education, 2018. DOI: &lt;a href=&quot;https://doi.org/10.1007/978-3-319-97085-1_1&quot;&gt;10.1007/978-3-319-97085-1_1&lt;/a&gt; &lt;a href=&quot;#fnref:RoboterFabrik&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:TeachingLab&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Kristy Strauss, “‘It’s a really cool place’: U of T Mississauga students get hands-on experience in new robotics teaching lab.” Accessed: April 25, 2023 &lt;a href=&quot;https://www.utoronto.ca/news/it-s-really-cool-place-u-t-mississauga-undergrads-get-hands-experience-new-robotics-teaching&quot;&gt;Online&lt;/a&gt; &lt;a href=&quot;#fnref:TeachingLab&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:16&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;S. Haddadin, S. Parusel, L. Johannsmeier, S. Golz, S. Gabl, F. Walch, M. Sabaghian, C. Jaehne, L. Hausperger, and S. Haddadin, “The Franka Emika Robot: A reference platform for robotics research and education,” IEEE Robotics &amp;amp; Automation Magazine, vol. 29, no. 2, pp. 46-64, 2022. DOI: &lt;a href=&quot;https://doi.org/10.1109/MRA.2021.3138382&quot;&gt;10.1109/MRA.2021.3138382&lt;/a&gt; &lt;a href=&quot;#fnref:16&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:16:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:13&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;J. Luh, W. Fisher, and R. Paul, “Joint torque control by a direct feedback for industrial robots,” Transactions on Automatic Control, vol. 28, no. 2, pp. 153–161, 1983. DOI: &lt;a href=&quot;https://doi.org/10.1109/TAC.1983.1103215&quot;&gt;10.1109/TAC.1983.1103215&lt;/a&gt; &lt;a href=&quot;#fnref:13&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:14&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;L. E. Pfeffer, O. Khatib, and J. Hake, “Joint torque sensory feedback in the control of a PUMA manipulator,” IEEE Transactions on Robotics and Automation, vol. 5, no. 4, pp. 418–425, 1989. DOI: &lt;a href=&quot;https://doi.org/10.1109/70.88056&quot;&gt;10.1109/70.88056&lt;/a&gt; &lt;a href=&quot;#fnref:14&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:15&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;R. Bischoff, J. Kurth, G. Schreiber, R. Koeppe, A. Albu-Schäffer, A. Beyer, O. Eiberger, S. Haddadin, A. Stemmer, G. Grunwald, and G. Hirzinger, “The kuka-dlr lightweight robot arm-a new reference platform for robotics research and manufacturing,” in International Symposium on Robotics, 2010, pp. 1–8. &lt;a href=&quot;https://ieeexplore.ieee.org/document/5756872&quot;&gt;online&lt;/a&gt; &lt;a href=&quot;#fnref:15&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:12&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;F. Grimminger, A. Meduri, M. Khadiv, J. Viereck, M. Wüthrich, M. Naveau, V. Berenz, S. Heim, F. Widmaier, T. Flayols, J. Fiene, A. Badri-Spröwitz, and L. Righetti, “An open torque-controlled modular robot architecture for legged locomotion research,” IEEE Robotics and Automation Letters, vol. 5, no. 2, pp. 3650–3657, 2020. DOI: &lt;a href=&quot;https://doi.org/10.1109/LRA.2020.2976639&quot;&gt;10.1109/LRA.2020.2976639&lt;/a&gt; &lt;a href=&quot;#fnref:12&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;M. Wüthrich, F. Widmaier, F. Grimminger, J. Akpo, S. Joshi, V. Agrawal, B. Hammoud, M. Khadiv, M. Bogdanovic, V. Berenz, J. Viereck, M. Naveau, L. Righetti, B. Schölkopf, and S. Bauer, “Trifinger: An open-source robot for learning dexterity,” in Conference on Robot Learning, 2020. arXiv: &lt;a href=&quot;https://doi.org/10.48550/arXiv.2008.03596&quot;&gt;2008.03596&lt;/a&gt; &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:RAM_Survey_2023&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;V. V. Patel, M. V. Liarokapis, and A. M. Dollar, “Open robot hardware: Progress, benefits, challenges, and best practices,” IEEE Robotics &amp;amp; Automation Magazine, pp. 2–9, 2022. DOI: &lt;a href=&quot;https://doi.org/10.1109/MRA.2022.3225725&quot;&gt;10.1109/MRA.2022.3225725&lt;/a&gt; &lt;a href=&quot;#fnref:RAM_Survey_2023&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Reinhard M. Grassmann</name></author><category term="hands-on" /><summary type="html">An open actuation module to create your continuum robots. One for all!</summary></entry><entry><title type="html">Beyond Medical Applications</title><link href="https://continuumroboticslab.github.io/opencontinuumrobotics/opinion/2023/03/17/untapped_potential.html" rel="alternate" type="text/html" title="Beyond Medical Applications" /><published>2023-03-17T00:00:00-04:00</published><updated>2023-03-17T00:00:00-04:00</updated><id>https://continuumroboticslab.github.io/opencontinuumrobotics/opinion/2023/03/17/untapped_potential</id><content type="html" xml:base="https://continuumroboticslab.github.io/opencontinuumrobotics/opinion/2023/03/17/untapped_potential.html">&lt;p&gt;Research on continuum robots has been primarily focussed on medical robotics. The common use case involes a physician teleoperating the continuum robot, who is in full control at all times. For instance in interventional medicine, a robotically-steered catheter or bronchoscope is essentially a long continuum robot whose tip is articulated while navigating through the vasculature or the airways. Although use in medical robotics is compelling, I argue that the opportunity space for continuum robotics remains largely unexploited as the medical focus restricted and constrained innovation in robot embodiment, control strategies, level of autonomy, and available feedback.&lt;/p&gt;

&lt;h2 id=&quot;why-are-continuum-robots-predominantly-explored-for-medicial-applications&quot;&gt;Why are Continuum Robots predominantly explored for medicial applications?&lt;/h2&gt;
&lt;p&gt;Looking at the history of continuum robotics, early research has focussed on larger scale continuum robots. Prototypes were built comparable in size to industrial serial arm robots. This probably resulted in expectations in terms of performance. If an industrial robot arm could achieve superior accuracy and repeatabilty with high payloads and at high speed, why would one need a continuum robot performing worse on this scale? Repeatability, accuracy, speed, and payload are clearly not unique selling points for continuum robots. Poised by the third industrial revolution in the late sixties and early seventies of the 20th century, roboticists naturally focussed on robots applicable to automation and its goals. Continuum robots were just not cutting it (yet). Consequently, continuum robotics remained a niche research area for a while.&lt;/p&gt;

&lt;p&gt;Medical robotics was just on the onset in the mid eighties and was using repurposed industrial robots. The first medical robotics procedure used the PUMA 560 robot to perform a neurosurgical biopsy at the National Hospital for Neurology and Neurosurgery in London in 1985. The robot guided a needle into the brain to take a tissue sample for examination. Fun fact: The Puma 560 design is based on an earlier robot design by Victor Scheinman, the same Victor Scheinman who developed the &lt;a href=&quot;https://www.cs.toronto.edu/~jbk/opencontinuumrobotics/history/2022/11/01/ORM.html&quot;&gt;first continuum robot&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The trend towards more minimally invasive surgey and ultimatley keyhole access to operate promises benefits for patient care, such as shorter hopsitalization and quicker recovery times. While industrial style robots certainly play an important role in medical robotics today, their large footprint and size naturally places them beside physicians and outside of the patient. But as soon as one wants to move away from large incisions and the need to open the body, thin, versatile, and dextrous robotics enters the scene. Small-scale continuum robots could sneak into a patient with more dextrous motion capabilties than conventional robots and the ability to reach surgical sites inaccessible by conventional robots or standard medical instruments! And that ability is more defining than accuracy and payload. In contrast to industrial automation, small-scale continuum robots promise significant benefit over serial robot arms!&lt;/p&gt;

&lt;p&gt;With medical applications, continuum robots found a compelling use case. Motivated by unsought of minimally-invasie approaches and the ability to navigate within the human body through natural orifices or miniscule inscisions, research in continuum robotics excelled. Over the past decades we have witnessed a vast surge in medical continuum robots. In fact, the majority of continuum robot papers draw their motivation from medical applications. The prominent surveys in the field of continuum robotics are centered around medicine&lt;sup id=&quot;fnref:BurgnerKahrs2015&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:BurgnerKahrs2015&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&quot;fnref:daVeiga2020&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:daVeiga2020&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&quot;fnref:Dupont2022&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:Dupont2022&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; and I refer the interested reader to those surveys to learn about the breadth and depth of medical continuum robotics research.&lt;/p&gt;

&lt;h2 id=&quot;the-untapped-potential&quot;&gt;The Untapped Potential&lt;/h2&gt;
&lt;p&gt;One may argue that continuum robots found their sweet spot in the medical application domain. While this is certainly the case, the untapped potential of continuum robots in non-medical applications is enormous! Think about autonomous small-scale or medium-scale continuum robots in in-situ and non-destructive inspection, maintenance, repair, and operations.&lt;/p&gt;

&lt;p class=&quot;notice&quot;&gt;&lt;strong&gt;Example&lt;/strong&gt;: On-wing jet engine inspection provides an example of a keyhole procedure, where a technician inspects components such as  turbine blades and the combustion chamber using a flexible camera, called a borescope, through tiny access points on the engine. This is a cumbersome procedure requiring an expert to fiddle with the borescope in hunched body postures, with limited time, as the plane stands ready for takeoff. If an issue is overlooked, e.g., a small crack in a blade, it may be disastrous and result in a worst-case scenario of the engine blowing off during flight. At the same time, full service of an engine means that it must be taken off-wing for maintenance – a costly endeavour. Only very few researcher worldwide look at this problem, with the University of Notthingham spearheading research with Rolls Royce on &lt;a href=&quot;https://www.nottingham.ac.uk/utc/research/robotics-for-in-situ-repair/robotics-for-in-situ-repair.aspx&quot;&gt;robotics for in-situ repair&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This in-situ inspection is just one of many examples where we can build on our expertise in continuum robotics in the medical domain and innovate the next generation of autonomous continuum robot systems. 
In fact, non-medical applications for continuum robots are characterized by similar challenges:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;limited accessiblity,&lt;/li&gt;
  &lt;li&gt;tortuous pathways in constrained environments, and&lt;/li&gt;
  &lt;li&gt;need for dextrous manipulation at the location of interest.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;At the same time, turning to new application domains opens new research questions challenging to solve:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;How can we design long continuum robots that can maintain stability?&lt;/li&gt;
  &lt;li&gt;How can we avoid buckling for continuum robots navigating cluttered environments?&lt;/li&gt;
  &lt;li&gt;How can we achieve dextrous steering and motion capalities and bear sufficient loads?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I envision a new generation of continuum robots that are of small and medium scale, dextrous enough to enter an environment for in-situ inspection, maintenance, and repair through multiple keyholes, which act autonomously and are able to collaborate with one another to achieve the task.&lt;/p&gt;

&lt;h2 id=&quot;call-to-action&quot;&gt;Call to Action&lt;/h2&gt;
&lt;p&gt;I believe, that we as the continuum robotics community, should turn to non-medical use-cases to invent this next-generation of continuum robot systems with autonomous capabilities. By focussing on medical applications, we have naturally limited our design choices to certain continuum robot dimensions, materials, workspaces, control paradigms, etc. that are informed by anatomical constraints and clinical requirements. In fact, most medical continuum robots are rather short if they can are designed to work in free spaces. Longer medical continuum robots need environmental constraints for steering - such as vasculature for robotic catheters.&lt;/p&gt;

&lt;p&gt;Drawing motivation from one application domain lead to narrow thinking and limited creativity. Continuum robotics researchers and innovators have become too focused on the specific needs and constraints of medicine. I argue that this prevented us from considering new and unconventional ideas!&lt;/p&gt;

&lt;p&gt;Overall, while focusing on medicine as the dominant application domain was necessary to develop expertise in continuum robotics, it is important for the continuum robotics community to maintain a broad perspective and engage with other fields and industries to encourage innovation and avoid limiting the potential for new and unconventional ideas.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:BurgnerKahrs2015&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;J. Burgner-Kahrs, D.C. Rucker, and H. Choset: Continuum Robots for Medical Applications: A Survey. IEEE Transactions on Robotics, 31(6), pp.1261–1280. doi: &lt;a href=&quot;https://doi.org/10.1109/TRO.2015.2489500&quot;&gt;10.1109/TRO.2015.2489500&lt;/a&gt; &lt;a href=&quot;#fnref:BurgnerKahrs2015&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:daVeiga2020&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;T. da Veiga, J.H. Chandler, P. Lloyd, G. Pittiglio,  N.J. Wilkinson, A.K. Hoshiar, R.A. Harris, and P. Valdastri: Challenges of continuum robots in clinical context: a review. Progress in Biomedical Engineering, 2(3): 032003, 2020. doi: &lt;a href=&quot;https://doi.org/10.1088/2516-1091/ab9f41&quot;&gt;10.1088/2516-1091/ab9f41&lt;/a&gt; &lt;a href=&quot;#fnref:daVeiga2020&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:Dupont2022&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;P.E. Dupont, N. Simaan, H. Choset, and D.C. Rucker: Continuum robots for medical interventions. Proceedings of the IEEE, 110(7):847-870, 2022. &lt;a href=&quot;https://doi.org/10.1109/JPROC.2022.3141338&quot;&gt;10.1109/JPROC.2022.3141338&lt;/a&gt; &lt;a href=&quot;#fnref:Dupont2022&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Jessica Burgner-Kahrs</name></author><category term="opinion" /><summary type="html">Opportunities for continuum robotics are largely unexploited, as the medical focus restricts and constrains innovation.</summary></entry><entry><title type="html">Tendon Routing Disks and their Effects on Motion Primitives</title><link href="https://continuumroboticslab.github.io/opencontinuumrobotics/101/2023/02/24/tendon-routing-disks.html" rel="alternate" type="text/html" title="Tendon Routing Disks and their Effects on Motion Primitives" /><published>2023-02-24T00:00:00-05:00</published><updated>2023-02-24T00:00:00-05:00</updated><id>https://continuumroboticslab.github.io/opencontinuumrobotics/101/2023/02/24/tendon-routing-disks</id><content type="html" xml:base="https://continuumroboticslab.github.io/opencontinuumrobotics/101/2023/02/24/tendon-routing-disks.html">&lt;p&gt;We have looked into the general &lt;a href=&quot;/opencontinuumrobotics/101/2022/10/28/motion-primitives.html&quot;&gt;motion primitives&lt;/a&gt; in continuum robotics: spatial bending, twisting, extension/contraction. Today, we look at partially constrained tendon paths and how the design of tendon routing disks influences the motion capabilities.&lt;/p&gt;

&lt;p&gt;Let’s recap: When we first looked at &lt;a href=&quot;/opencontinuumrobotics/101/2022/11/11/tdcr-intro.html&quot;&gt;tendon-driven continuum robots&lt;/a&gt;, we looked at the most general design, i.e. with tendon routing disks at equidistant spacing afixed to a a flexible backbone. Tendons terminate at the end disk of each segment to actuate it. Most generally, these tendons are routed in parallel to the central backbone. For spatial bending either 3 separate tendons or 2 antagonistic tendon pairs are used. To achieve a tendon-driven continuum robot segment capable of all motion primitive, we will expand our understanding of tendon routing disks and its implications.&lt;/p&gt;

&lt;p&gt;Let’s conceptually think about tendon routing disks. They provide channels to route the tendon actuating a continuum robot.  We depict four conceptual tendon routing disk types below. The dotted arrows indicate the degree of freedom of the disks themselves and the solid arrows indicate the motion primitives achievable. We omit the tendon themselves in the drawings.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://continuumroboticslab.github.io/opencontinuumrobotics/assets/images/posts/101_FSD.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The most common type is afixed to a central backbone and routes the tendons with a fixed distance parallel to the backbone. We refer to this type of tendon routing disk as&lt;/p&gt;

&lt;dl&gt;
  &lt;dt&gt;&lt;strong&gt;Type-0&lt;/strong&gt;&lt;/dt&gt;
  &lt;dd&gt;A tendon routing disk which is fixed and can neither rotate nor translate along the backbone.&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;Fixing the tendon routing disks to the central backbone is the most restrictive as they only allow for bending. Allowing the tendon routing disks to freely translate along the central backbone allows for extension.&lt;/p&gt;

&lt;dl&gt;
  &lt;dt&gt;&lt;strong&gt;Type-I&lt;/strong&gt;&lt;/dt&gt;
  &lt;dd&gt;A translational spacer disk which can freely translate along the backbone but not rotate.&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;Most realizations of this tendon routing disk type ensure equidistant spacing of the disks as the backbone extends and contracts. This is either achieved by compression springs between disks or magnets within the disks alternating polarity for repulsion.&lt;/p&gt;

&lt;p&gt;Conceptually, tendon routing disks may also be freely rotating about the central backbone, but constrained in position along the backbone. Such a tendon routing would enable bending but also twist as the tendon route is not constrained to being parallel.&lt;/p&gt;

&lt;dl&gt;
  &lt;dt&gt;&lt;strong&gt;Type-II&lt;/strong&gt;&lt;/dt&gt;
  &lt;dd&gt;A rotational space disk which can freely rotate about the backbone while translation is prohibited.&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;We fabricated a tendon-driven continuum robot segment using type-II disks. The end disk is rigidly attached to the backbone rod which can rotate about its axis. The base disk is fixed in orientation. The image series below  shows different rotation angles $\alpha$.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://continuumroboticslab.github.io/opencontinuumrobotics/assets/images/posts/101-type-ii-example.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Ultimately, the least restrictive tendon routing disk is free to rotate and translate along the central backbone. Consequently, the tendon routing can allow for parallel and non-parallel tendon paths for bending and twisting, while also allowing for extension.&lt;/p&gt;

&lt;dl&gt;
  &lt;dt&gt;&lt;strong&gt;Type-III&lt;/strong&gt;&lt;/dt&gt;
  &lt;dd&gt;A spacer disk which can translate along and rotate freely about the backbone.&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;Building on our extensible tendon-driven continuum robot design, we have fabricated a tendon-driven continuum robot segment with type-III disks. The image series below shows the prototype at various backbone rotation angles and applied tendon loads. The flag at the tip indicated the central backbone rotation angle. In addition to bending a twist can be observed. 
&lt;img src=&quot;https://continuumroboticslab.github.io/opencontinuumrobotics/assets/images/posts/101-type-iii-example.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The image series below shows the type-III tendon disk prototype contracting while also adjusting the rotation angle. 
&lt;img src=&quot;https://continuumroboticslab.github.io/opencontinuumrobotics/assets/images/posts/101-type-iii-extension-example.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;notice--success&quot;&gt;&lt;strong&gt;Further Reading&lt;/strong&gt;: You want to read more on tendon routing disk types and the prototypes shown above? Check out our open access paper in Frontiers in Robotics &amp;amp; AI&lt;sup id=&quot;fnref:Grassmann&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:Grassmann&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:Grassmann&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;R.M. Grassmann, P. Rao, Q. Peyron, J. Burgner-Kahrs: FAS—A Fully Actuated Segment for Tendon-Driven Continuum Robots. Frontiers in Robotocs and AI, 9:873446, 2022. doi: &lt;a href=&quot;https://doi.org/10.3389/frobt.2022.873446&quot;&gt;10.3389/frobt.2022.873446&lt;/a&gt; &lt;a href=&quot;#fnref:Grassmann&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Jessica Burgner-Kahrs</name></author><category term="101" /><summary type="html">Let&apos;s conceptually think about tendon routing disks. They provide channels to route the tendon actuating a continuum robot.</summary></entry><entry><title type="html">CRVisToolkit: Visualizing Concentric Tube Continuum Robots</title><link href="https://continuumroboticslab.github.io/opencontinuumrobotics/hands-on/2023/02/17/CRVis-ctcr.html" rel="alternate" type="text/html" title="CRVisToolkit: Visualizing Concentric Tube Continuum Robots" /><published>2023-02-17T00:00:00-05:00</published><updated>2023-02-17T00:00:00-05:00</updated><id>https://continuumroboticslab.github.io/opencontinuumrobotics/hands-on/2023/02/17/CRVis-ctcr</id><content type="html" xml:base="https://continuumroboticslab.github.io/opencontinuumrobotics/hands-on/2023/02/17/CRVis-ctcr.html">&lt;p&gt;In our second release of the Continuum Robot Visualization Toolkit (&lt;a href=&quot;https://github.com/ContinuumRoboticsLab/CRVisToolkit&quot;&gt;CRVisToolkit&lt;/a&gt;), you will find a new set of MATLAB functions for visualization and plotting of concentric tube continuum robots (CTCR). With a framed curve represented by a series $n$ of 4x4 homogeneous transformation matrices (reshaped columnwise into a $n$x16 vector), indices of the tube end points, as well as the tube radii as input, you to create a MATLAB figure. In addition, we provide a utility function &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;robotindependentmapping(kappa, phi, ell, ptsperseg)&lt;/code&gt; which generates a framed backbone curve using constant curvature arc parameters and the desired number of points (per segment) as input.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://continuumroboticslab.github.io/opencontinuumrobotics/assets/images/posts/hands-on/ctcr_vis_MATLAB.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-matlab highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;draw_ctcr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tube_end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r_tube&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;% DRAW_CTCR Creates a figure of a concentric tube continuum robot (ctcr)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%   Takes a matrix with nx16 entries, where n is the number&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%   of points on the backbone curve. For each point on the curve, the 4x4&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%   transformation matrix is stored columnwise (16 entries). The x- and&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%   y-axis span the material orientation and the z-axis is tangent to the&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%   curve.&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%   INPUT&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%   g(n,16): backbone curve with n 4x4 transformation matrices reshaped into 1x16 vector (columnwise)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%   tube_end(1,m): indices of g where ctcr tubes terminate&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%   r_tube(1,m): radii of tubes&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%   options:&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%       tipframe (shows tip frame, default true/1)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%       baseframe (shows robot base frame, default false/0)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%       projections (shows projections of backbone curve onto&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%                    coordinate axes, default false/0)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%       baseplate (shows robot base plate, default false/0)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We provide an example file &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ctcr_draw_example.m&lt;/code&gt; to create a figure of a CTCR with three tubes. The example also makes use of the new utility function &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;robotindependentmapping(kappa, phi, ell, ptsperseg)&lt;/code&gt;. This function takes &lt;a href=&quot;/opencontinuumrobotics/101/2022/12/02/cc-kinematics.html&quot;&gt;constant curvature parameters&lt;/a&gt; and generates a backbone curve. This backbone curve $g$ is in the format required by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;draw_ctcr(g,tube_end,r_tube,options)&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;draw_tdcr(g,seg_end,r_disk,r_height,options)&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-matlab highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;robotindependentmapping&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kappa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ell&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ptsperseg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;% ROBOTINDEPENDENTMAPPING creates a framed curve for given configuration parameters&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%   EXAMPLE&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%       g = robotindependentmapping([1/40e-3;1/10e-3],[0,pi],[25e-3,20e-3],10)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%       creates a 2-segment curve with radius of curvatures 1/40 and 1/10&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%       and segment lengths 25 and 20, where the second segment is rotated by pi rad.&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%   INPUT: configuration parameters&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%       kappa (nx1): segment curvatures&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%       phi (nx1): segment bending plane angles&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%       l (nx1): segment lengths&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%       ptsperseg (nx1): number of points per segment&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%                        if n=1 all segments with equal number of points&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%   OUTPUT: backbone curve&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%       g (n,16): backbone curve with n 4x4 transformation matrices reshaped into 1x16 vector (columnwise)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Find out more and test CRVisToolkit on &lt;a href=&quot;https://github.com/ContinuumRoboticsLab/CRVisToolkit&quot; class=&quot;btn btn--success&quot;&gt;GitHub&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Happy continuum robot visualization!&lt;/p&gt;

&lt;p class=&quot;notice--info&quot;&gt;The CRVisToolkit stems from the &lt;a href=&quot;https://crl.utm.utoronto.ca&quot;&gt;Continuum Robotics Laboratory&lt;/a&gt; MATLAB codebase that grew over the past decade of our research activities. Numerous students contributed in one way or the other to the CTCR visualization and are acknowledged here in no particular order: Josephine Granna, Sven Lilge, and Malte Bormann.&lt;/p&gt;</content><author><name>Jessica Burgner-Kahrs</name></author><category term="hands-on" /><summary type="html">CRVisToolkit now provides utilities to create professional looking plots of concentric tube continuum robots using MATLAB.</summary></entry><entry><title type="html">A Short History on Concentric Tube Continuum Robots</title><link href="https://continuumroboticslab.github.io/opencontinuumrobotics/history/2023/02/07/ctcr-history.html" rel="alternate" type="text/html" title="A Short History on Concentric Tube Continuum Robots" /><published>2023-02-07T00:00:00-05:00</published><updated>2023-02-07T00:00:00-05:00</updated><id>https://continuumroboticslab.github.io/opencontinuumrobotics/history/2023/02/07/ctcr-history</id><content type="html" xml:base="https://continuumroboticslab.github.io/opencontinuumrobotics/history/2023/02/07/ctcr-history.html">&lt;p&gt;The continuum robotics community usually refers to two papers when it comes to acknowledging the first appearance of concentric tube continuum robots. They both appeared at the same conference, IEEE International Conference on Intelligent Robots and Systems (IROS), the same year (2006), presented in the same session, one after the other, from two different author groups: (1) P. Sears and P. Dupont&lt;sup id=&quot;fnref:Dupont&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:Dupont&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; and (2) R.J. Webster III, A. Okamura, and N.J. Cowan&lt;sup id=&quot;fnref:Webster&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:Webster&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;. &lt;em&gt;(Note: ordered alhpabetically by first author)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Sears &amp;amp; Dupont refer to the idea as&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;a steerable needle technology using curved concentric tubes&lt;sup id=&quot;fnref:Dupont:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:Dupont&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;and Webster, Okamura &amp;amp; Cowan refer to the idea as&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;continuously ﬂexible snake-like robots, called active cannulas, that consist of several telescoping pre-curved superelastic tubes&lt;sup id=&quot;fnref:Webster:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:Webster&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;What is less known, is the fact that the concept of a robotic device using concentric precurved tubes was already introduced one year earlier, in 2005, by Furusho et al.&lt;sup id=&quot;fnref:Furusho&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:Furusho&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; at the IEEE International Conference on Mechatronics &amp;amp; Automation. They provide a conceptual drawing of what they call a&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;curved multi-tube catheter&lt;sup id=&quot;fnref:Furusho:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:Furusho&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;consisting of an outer and inner guide, both precurved elastic tubes, and a third innermost tube/needle. Furusho et al. state the kinematics of this robotic device and present a motorized prototype that they teleoperated.&lt;/p&gt;

&lt;p&gt;This is not to say that Furusho et al. was not recognized. Their work has been acknowledged, but just not as much. The number of citations (obtained from Google Scholar on Jan 27, 2023) show a quite drastic difference. It is hard to tell, and would be pure speculation, why the two papers from IROS 2006 are more often cited than Furusho et al. &lt;strong&gt;And yet, as we are all standing on the shoulders of giants in academia, we should not forget those who paved the way and published innovative ideas first.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://continuumroboticslab.github.io/opencontinuumrobotics/assets/images/posts/history/ctcr_first_citations.jpg&quot; alt=&quot;image&quot; style=&quot;float: center&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;notice&quot;&gt;In his PhD thesis, available open-access &lt;a href=&quot;https://ir.vanderbilt.edu/handle/1803/13344?show=full&quot;&gt;here&lt;/a&gt;, Hunter Gilbert provides a thorough comprehensive historical perspective on the origin of curved mutli-tube medical tools and how those relate to concentric tube continuum robots in Section 1.1. This section is also part of Gilbert, Rucker &amp;amp; Webster&lt;sup id=&quot;fnref:Gilbert&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:Gilbert&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt; review paper on concentric tube continuum robots.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:Dupont&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;P. Sears &amp;amp; P. Dupont: A Steerable Needle Technology Using Curved Concentric Tubes. IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 2850-2856, 2006. doi: &lt;a href=&quot;https://doi.org/10.1109/IROS.2006.282072&quot;&gt;10.1109/IROS.2006.282072&lt;/a&gt; &lt;a href=&quot;#fnref:Dupont&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:Dupont:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:Webster&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;R. J. Webster, A. M. Okamura, N. J. Cowan: Toward Active Cannulas: Miniature Snake-Like Surgical Robots. IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 2857-2863, 2006. doi: &lt;a href=&quot;https://doi.org/10.1109/IROS.2006.282073&quot;&gt;10.1109/IROS.2006.282073&lt;/a&gt;. &lt;a href=&quot;#fnref:Webster&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:Webster:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:Furusho&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;J. Furusho, T. Ono, R. Murai, T. Fujimoto, Y. Chiba, H. Horio: Development of a curved multi-tube (CMT) catheter for percutaneous umbilical blood sampling and control methods of CMT catheters for solid organs. IEEE International Conference Mechatronics and Automation, pp. 410-415, 2005. doi: &lt;a href=&quot;https://doi.org/10.1109/ICMA.2005.1626582&quot;&gt;10.1109/ICMA.2005.1626582&lt;/a&gt; &lt;a href=&quot;#fnref:Furusho&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:Furusho:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:Gilbert&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;H.B. Gilbert, D.C. Rucker,  R.J. Webster III: Concentric Tube Robots: The State of the Art and Future Directions. International Symposium on Robotics Research, pp. 253–269, 2016. &lt;a href=&quot;https://doi.org/10.1007/978-3-319-28872-7_15&quot;&gt;https://doi.org/10.1007/978-3-319-28872-7_15&lt;/a&gt;. &lt;a href=&quot;#fnref:Gilbert&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Jessica Burgner-Kahrs</name></author><category term="history" /><summary type="html">The first concentric tube continuum robot was published in 2005! And yet, the community usually refers to two papers from 2006 as the first. Why?</summary></entry><entry><title type="html">Constant-Curvature Modeling of Concentric Tube Continuum Robots</title><link href="https://continuumroboticslab.github.io/opencontinuumrobotics/101/2023/01/27/ctcr-cc-model.html" rel="alternate" type="text/html" title="Constant-Curvature Modeling of Concentric Tube Continuum Robots" /><published>2023-01-27T00:00:00-05:00</published><updated>2023-01-27T00:00:00-05:00</updated><id>https://continuumroboticslab.github.io/opencontinuumrobotics/101/2023/01/27/ctcr-cc-model</id><content type="html" xml:base="https://continuumroboticslab.github.io/opencontinuumrobotics/101/2023/01/27/ctcr-cc-model.html">&lt;p&gt;Today, we are looking at how &lt;a href=&quot;/opencontinuumrobotics/101/2022/11/18/ctcr-intro.html&quot;&gt;concentric tube continuum robots&lt;/a&gt; (CTCR) are modelled using the &lt;a href=&quot;/opencontinuumrobotics/101/2022/12/02/cc-kinematics.html&quot;&gt;constant curvature kinematics framework&lt;/a&gt;.
We derive the mapping for general CTCR composed of multiple tubes and then discuss the
limitations.&lt;/p&gt;

&lt;p&gt;Under the assumption that the robot’s shape is composed of
constant curvature segments, it can be expressed as a concatenation of
multiple circular arcs. Each circular arc corresponds to one segment \(i\)
and each segment is described by its length \(\ell_{i}\), curvature
\(\kappa_{i}\), and bending plane angle \(\phi_{i}\). To determine the robot
dependent mapping for a CTCR, we need to identify the number \(m\) of
segments present. As a segment is characterized by constant curvature,
we have to locate transitions points along the robot where the curvature
changes.&lt;/p&gt;

&lt;h2 id=&quot;robot-parameters&quot;&gt;Robot Parameters&lt;/h2&gt;

&lt;p&gt;We identify a tube within the CTCR with index
\(j \in \lbrack 1,N_{t}\rbrack\) where \(N_{t}\) is the number of tubes,
\(j = 1\) is the innermost tube, and \(j = N_{t}\) is the outermost tube.
Each tube is characterized by it length \(L_{j} = L_{j}^{s} + L_{j}^{c}\)
where \(L_{j}^{s}\) is the length of the straight section and \(L_{j}^{c}\)
is the length of the curved section (see Figure 5 left). We assume that
the curved section has constant curvature \(\kappa_{j}^{*}\). The
precurvature of a tube is deﬁned in the xz-plane, where the z axis is
tangential to the tube’s straight section pointing to the tip.
Furthermore, each tube’s outer \(\text{OD}_{j}\) and inner \(\text{ID}_{j}\)
diameter are specified. Lastly, the modulus of elasticity \(E_{j}\)
(Young’s modulus) is determined by
the tube’s material. Superelastic NiTi tubes
typically come with elastic modulus of \(28 - 83\) GPa.&lt;/p&gt;

&lt;p&gt;The CTCR joint space is given as
\(\mathbf{q} = \lbrack\alpha_{1},\ldots,\alpha_{N_{t}},\beta_{1},\ldots,\beta_{N_{t}}\rbrack\)
where \(\alpha_{j} \in \lbrack - \pi,\pi)\) is the rotation angle about
the z-axis and \(\beta_{j} \in \lbrack - L_{j},0\rbrack\) is the
translation along the z-axis of tube \(j\). If all \(\alpha_{j} = 0\), the
centreline stays in the x-z-plane and curves toward the positive x axis.
The translational joint variables are subject to the following
constraints&lt;/p&gt;

\[\beta_{1} \leq \ldots \leq \beta_{N_{t}} \leq 0\]

&lt;p&gt;and&lt;/p&gt;

\[L_{N_{t}} + \beta_{N_{t}} \leq \ldots \leq L_{1} + \beta_{1}\]

&lt;p&gt;These arise from the telescoping nature of the tube assembly and the
actuation principle, i.e., each tube can be retracted at maximum by its
own length. Furthermore, we require the tubes to extend one another
outside the actuation unit and to not be fully retracted within any more
outer tube. In the robot’s zero position, all tubes are fully retracted
and align with the front plate of the actuation unit. Below, we illustrate the joint space of a CTCR with \(N_{t} = 3\) and the base
coordinate frame.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://continuumroboticslab.github.io/opencontinuumrobotics/assets/images/posts/cr_101_ctcr_model_parameter.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The robot dependent mapping is based on the principles of beam mechanics
to solve the forward kinematic problem. We assume the tubes to deform
only in bending and not in twisting, such that the resulting centerline
curvature can be computed in closed-form based on a moment equilibrium
by applying Bernoulli–Euler beam mechanics.&lt;/p&gt;

&lt;h2 id=&quot;resultant-curvature-of-concentric-tubes&quot;&gt;Resultant Curvature of Concentric Tubes&lt;/h2&gt;

&lt;p&gt;To describe the complete shape of a CTCR, we will ﬁrst develop a model
for the shape of a single segment composed of several fully overlapping
concentric curved tubes. Let’s first consider the example depicted here.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://continuumroboticslab.github.io/opencontinuumrobotics/assets/images/posts/cr_101_ctcr_cc_model_equilibrium.png&quot; alt=&quot;image&quot; style=&quot;float: center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For a collection of two tubes with circular precurvatures
\(\kappa_{1}^{*}\) and \(\kappa_{2}^{*}\), once inserted into each other,
the resultant constant curvature \(\kappa\) is common to both tubes. Here,
the tubes have not been axially rotated with respect to one another and
their natural curvature planes are aligned. The bending moments \(M_{j}\)
(in Nm) will be constant along the length of each tube and can be
described by&lt;/p&gt;

\[M_{1} = (\kappa - \kappa_{1}^{*})EI_{1}\]

&lt;p&gt;and&lt;/p&gt;

\[M_{2} = (\kappa - \kappa_{2}^{*})EI_{2}\]

&lt;p&gt;where \(E\) is the Young’s modulus (in Pa), and \(I_{1}\) and \(I_{2}\) are
the second area moment (in \(m^{4}\)) of the symmetric cross section of
the respective tube. The second area moment \(I\) is a geometrical
property of the tube’s cross section area which reflects how its points
are distributed with regard to the central axis. As a
tube’s &lt;img src=&quot;https://continuumroboticslab.github.io/opencontinuumrobotics/assets/images/posts/cr_101_ctcr_tube_cross_section.png&quot; alt=&quot;image&quot; style=&quot;float: right&quot; /&gt; 
cross section is an annulus, the second
area moment can be determined from the inner and outer diameter as&lt;/p&gt;

\[I_{j} = \frac{\pi}{64}(\text{OD}_{j}^{4} - \text{ID}_{j}^{4})\]

&lt;p&gt;We can describe the resultant curvature of these two overlapping tubes
by evaluating the moment equilibrium&lt;/p&gt;

\[M_{1} + M_{2} = 0\]

&lt;p&gt;and resolving for&lt;/p&gt;

\[\kappa = \frac{EI_{1}\kappa_{1}^{*} + EI_{2}\kappa_{2}^{*}}{EI_{1} + EI_{2}}\]

&lt;p&gt;This can be generalized to collections of \(N_{t}\) axially aligned tubes&lt;/p&gt;

\[\kappa = \frac{\sum_{j = 1}^{N_{t}}EI_{j}\kappa_{j}^{*}}{\sum_{j = 1}^{N_{t}}EI_{j}}\]

&lt;p&gt;Let’s now consider the example depicted here.&lt;img src=&quot;https://continuumroboticslab.github.io/opencontinuumrobotics/assets/images/posts/cr_101_ctcr_cc_bending_plane.png&quot; alt=&quot;image&quot; style=&quot;float: right&quot; /&gt; When precurved
tubes are rotated axially, their natural planes of curvature are no
longer aligned and the direction of the bending moments they apply
changes. The tubes exert a moment on one another about their respective
y-axes, which is caused by their initial precurvature about this
direction. The tubes are rotated by angles \(\alpha_{1}\) and
\(\alpha_{2}\), and the equilibrium plane angle is \(\phi\). As before, each
tube experiences a constant bending moment
\(M_{1} = (\kappa - \kappa_{1}^{*})EI_{1}\) and
\(M_{2} = (\kappa - \kappa_{2}^{*})EI_{2}\), but now these bending moments
have two component projections on the base frame x and y axes. The
equilibrium state \(M_{1} + M_{2} = 0\) yields&lt;/p&gt;

&lt;p&gt;\(\begin{bmatrix}
\kappa_{x} \\
\kappa_{y} \\
\end{bmatrix} = \frac{1}{EI_{1} + EI_{2}}\begin{pmatrix}
EI_{1}\kappa_{1}^{*}\lbrack\begin{matrix}
\cos\alpha_{1} \\
\sin\alpha_{1} \\
\end{matrix}\rbrack + EI_{2}\kappa_{2}^{*}\lbrack\begin{matrix}
\cos\alpha_{2} \\
\sin\alpha_{2} \\
\end{matrix}\rbrack \\
\end{pmatrix}\).&lt;/p&gt;

&lt;p&gt;For general number of concentric tubes, this can be generalized to&lt;/p&gt;

\[\begin{bmatrix}
\kappa_{x} \\
\kappa_{y} \\
\end{bmatrix} = \frac{1}{\sum_{j = 1}^{N_{t}}EI_{j}}\overset{N_{t}}{\sum_{j = 1}}EI_{j}\kappa_{j}^{*}\begin{bmatrix}
\cos\alpha_{j} \\
\sin\alpha_{j} \\
\end{bmatrix}(Eq. 1)\]

&lt;p&gt;Given the components of the resultant curvature, we can determine the
bending plane angle \(\phi = \text{atan2}(\kappa_{y},\kappa_{x})\) and
curvature \(\kappa = \sqrt{\kappa_{x}^{2} + \kappa_{y}^{2}}\). Note, that
\(\phi\) is undefined for straight segments, i.e., for zero curvature as
\(\text{atan}2(0,0) = \text{nan}\). In this special case, the rotation
angle \(\alpha\) of the outermost present tube in the segment is used as
\(\phi\).&lt;/p&gt;

&lt;h2 id=&quot;determining-the-arc-parameters-of-a-ctcr&quot;&gt;Determining the Arc Parameters of a CTCR&lt;/h2&gt;

&lt;p&gt;The first step in determining the robot dependent mapping of a CTCR is
determining the number of segments \(m\) and their lengths \(\ell_{i}\) for
\(i \in \lbrack 1,m\rbrack\). These are deﬁned by transition point
locations, where the component tubes either end or transition from their
straight to curved section. The set \(T\) of transition points can be
determined as algebraic functions of the tube geometry and the
translational joint positions \(\beta_{j}\)&lt;/p&gt;

\[T = \text{sort}_{\text{asc}}\{ 0,\beta_{n} + L_{n}^{s},\beta_{n} + L_{n},\ldots\beta_{1} + L_{1}^{s},\beta_{1} + L_{1}\}\]

&lt;p&gt;From the resulting values of the set T, all duplicate elements are
omitted, i.e., tube sections terminate at the same location, as well as
all elements \(&amp;lt; 0\), i.e., the respective tube section is located within
the actuation unit. While the maximum number of segments is \(2N_{t}\),
the number of actual segments is dependent on the current joint values
\(\mathbf{q}\) as some segments might be located within the actuation
unit. Here, we show an example of a CTCR composed of three tubes and
its transition points.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://continuumroboticslab.github.io/opencontinuumrobotics/assets/images/posts/cr_101_ctcr_cc_tube_transitions.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Using the transition points T, the length of the constant curvature
segments of the CTCR can be determined as&lt;/p&gt;

\[\begin{matrix}
\ell_{1} &amp;amp; = T_{1} - T_{0} \\
\ell_{2} &amp;amp; = T_{2} - T_{1} \\
\ldots &amp;amp; \\
\ell_{m} &amp;amp; = T_{m} - T_{m - 1} \\
\end{matrix}\]

&lt;p&gt;In a second step, we can determine \(\kappa_{x}\) and \(\kappa_{z}\) for
each segment \(i \in \lbrack 1,m\rbrack\) enclosed by the transition
points \(\lbrack T_{i - 1},T_{i}\rbrack\) using Equation (\(1\)), and then
\(\kappa_{i}\) and \(\phi_{i}\). Note, that not all tubes are present in
each segment, such that only the present ones with their respective
parameters have to be considered (either zero curvature in straight tube
sections or the respective precurvature in curved sections, alongside ID
and OD, as well as \(E\)).&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;/opencontinuumrobotics/101/2022/12/02/cc-kinematics.html&quot;&gt;constant curvature kinematics franmework&lt;/a&gt; assumes that \(\phi\) is
expressed locally, i.e., w.r.t. the previous segment for
the robot independent mapping. Consequently, after determining
\(\phi_{i}\) expressed in the base frame for each segment using Equation
(\(1\)), we will need to apply a final correction step&lt;/p&gt;

&lt;p&gt;\(\phi_{i} = \phi_{i} - \phi_{i - 1}\).&lt;/p&gt;

&lt;h2 id=&quot;remarks&quot;&gt;Remarks&lt;/h2&gt;

&lt;p&gt;The model introduced today makes multiple simplifying
assumptions, i.e., pure bending, no torsional deformation, no friction,
no effect of gravitation and external forces. The assumption of infinite
torsional rigidity in the tubes is only reasonable as long as the
relative rotation angles between the tubes are small and the straight
sections of each tube are short. Considering torsional deformation is
particularly important in the straight transmission sections of the
tubes that lie between the actuators and the first curved link, since
these transmissions are long relative to the curved sections. In fact,
despite the simple actuation of component tubes, the resulting motion of
CTCR is characterized by a highly non-linear behaviour due to the
elastic interactions between the tubes.&lt;/p&gt;

&lt;p&gt;An advanced modelling approach is to leverage the elasticity theory, in
particular the Cosserat theory of elastic rods. This involves writing
rod equation for each tube, and then enforce concentricity by requiring
all tubes to conform to the same curvature as a function of arc-length,
leaving them free to rotate axially with respect to each other. This
results in a system of differential equations with mixed boundary
conditions. The boundary conditions at the base of the robot are the
axial angles of the tubes, and the boundary conditions at the tip are
internal moments that vanish because there is no material beyond the tip
to support them. Note that after this mechanics problem is solved, to
determine the axial tube angles, one must still integrate along the
robot to determine the space curve of the robot itself. Experimental
testing of the model has shown that with calibration, mean error in the
prediction of tip position can be as low as 1% to 3% of overall robot
length. With typical CTCR length of 200-300mm, this means that we can
estimate the pose of the tip with an error of about 2-9 mm. This is the
most accurate model existing for CTCR to date. As this 101 category of the OpenContinuumRobotics Blog is an
introduction to continuum robotics, we do not cover advanced modelling approaches for CTCR (yet!).&lt;/p&gt;

&lt;h2 id=&quot;further-reading&quot;&gt;Further Reading&lt;/h2&gt;

&lt;p&gt;Webster, R.J. &amp;amp; Jones, B.A., 2010. Design and Kinematic Modeling of
Constant Curvature Continuum Robots: A Review. The International Journal
of Robotics Research, 29(13), pp. 1661–1683.
&lt;a href=&quot;https://doi.org/10.1177%2F0278364910368147&quot;&gt;https://doi.org/10.1177/0278364910368147&lt;/a&gt;&lt;br /&gt;
Section 3.2.3&lt;/p&gt;

&lt;p&gt;Mahoney, A.W., Gilbert, H.B., Webster, R.J., 2018. A Review of
Concentric Tube Robots: Modeling, Control, Design, Planning, and
Sensing. The Encyclopedia of Medical Robotics, Chapter 7, pp. 181-202.
&lt;a href=&quot;https://doi.org/10.1142/9789813232266_0007&quot;&gt;https://doi.org/10.1142/9789813232266_0007&lt;/a&gt;&lt;/p&gt;</content><author><name>Jessica Burgner-Kahrs</name></author><category term="101" /><summary type="html">A simple free-space model for CTCR.</summary></entry><entry><title type="html">Visualizing Tendon-driven Continuum Robots in MATLAB</title><link href="https://continuumroboticslab.github.io/opencontinuumrobotics/hands-on/2023/01/24/openCRVis.html" rel="alternate" type="text/html" title="Visualizing Tendon-driven Continuum Robots in MATLAB" /><published>2023-01-24T00:00:00-05:00</published><updated>2023-01-24T00:00:00-05:00</updated><id>https://continuumroboticslab.github.io/opencontinuumrobotics/hands-on/2023/01/24/openCRVis</id><content type="html" xml:base="https://continuumroboticslab.github.io/opencontinuumrobotics/hands-on/2023/01/24/openCRVis.html">&lt;p&gt;You have probably looked at continuum robotics papers and seen nice plots and visualizations. Or you have implemented your first continuum robot model which outputs a curve representing the backbone and are now wondering how to visualize your robot. Today, we provide you with utilities to create professional looking plots of tendon-driven continuum robots using MATLAB.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://continuumroboticslab.github.io/opencontinuumrobotics/assets/images/posts/hands-on/tdcr_vis_MATLAB.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In our initial release of the Continuum Robot Visualization Toolkit (&lt;a href=&quot;https://github.com/ContinuumRoboticsLab/CRVisToolkit&quot;&gt;CRVisToolkit&lt;/a&gt;), you will find a set of MATLAB functions for visualization and plotting of continuum robots, in particular tendon driven continuum robots (TDCR). It takes a curve represented by a series $n$ of 4x4 homogeneous transformation matrices (reshaped columnwise into a $n$x16 vector), indices of the segment end points, as well as radius and disk height as input to create a MATLAB figure. We assume that the TDCR is operated by three tendons at $120$ degrees radial offset.&lt;/p&gt;

&lt;div class=&quot;language-matlab highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;draw_tdcr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seg_end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r_disk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r_height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%   Creates figure of a tendon-driven continuum robot (tdcr)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%   Takes a matrix with nx16 entries, where n is the number&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%   of points on the backbone curve. For each point on the &lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%   curve, the 4x4 transformation matrix is stored columnwise &lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%   (16 entries). The x- and y-axis span the material &lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%   orientation and the z-axis is tangent to the curve.&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%   INPUT&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%   g(n,16): backbone curve with n 4x4 transformation &lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%            matrices reshaped into 1x16 vector (columnwise) &lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%   seg_end(1,m): indices of g where tdcr segments terminate&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%   r_disk: radius of spacer disks&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%   r_height: height of space disks&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%   options: &lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%       tipframe (shows tip frame, default true/1)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%       segframe (shows segment end frames, default false/0)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%       baseframe (shows robot base frame, default false/0)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%       projections (shows projections of backbone curve onto &lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%                    coordinate axes, default false/0)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%       baseplate (shows robot base plate, default false/0)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;To get you started, we provide three sample curves to generate three drawings.&lt;/p&gt;

&lt;div class=&quot;language-matlab highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;load&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tdcr_curve_examples&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mat&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;fig1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;draw_tdcr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;onesegtdcr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fig2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;draw_tdcr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;threesegtdcr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;projections&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;baseplate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fig3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;draw_tdcr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;foursectdcr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;45&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;segframe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;baseframe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; &lt;/p&gt;

&lt;p&gt;Find out more and test CRVisToolkit on &lt;a href=&quot;https://github.com/ContinuumRoboticsLab/CRVisToolkit&quot; class=&quot;btn btn--success&quot;&gt;GitHub&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Stay tuned for updates on the CRVisToolkit. Coming soon: utility functions, such as the robot independent mapping for the constant curvature kinematics frameworks, and concentric tube continuum robot visualization functions!&lt;/p&gt;

&lt;p class=&quot;notice--info&quot;&gt;The CRVisToolkit stems from the &lt;a href=&quot;https://crl.utm.utoronto.ca&quot;&gt;Continuum Robotics Laboratory&lt;/a&gt; MATLAB codebase that grew over the past decade of our research activities. Numerous students contributed in one way or the other and are acknowledged here in no particular order: Maria Neumann, Josephine Granna, Sven Lilge, Ernar Amanov, Priyanka Rao.&lt;/p&gt;</content><author><name>Jessica Burgner-Kahrs</name></author><category term="hands-on" /><summary type="html">Launching the CRVisToolkit providing you with utilities to create professional looking plots of tendon-driven continuum robots using MATLAB.</summary></entry></feed>